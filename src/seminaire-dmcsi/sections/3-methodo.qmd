## Segmentation s√©mantique

- [**Vision par ordinateur**]{.orange}  
- [**Classer chaque pixel**]{.blue2} d‚Äôune image  
- Pour nos besoins : conna√Ætre les pixels de [**cat√©gorie "b√¢tie"**]{.orange}   

<div style="text-align:center;">
  ![Exemple de segmentation "b√¢timent"](../img/segmentation.png){width=30%}
</div>

::: notes
Pour d√©tecter le b√¢ti de fa√ßon automatique, nous nous sommes tourn√© vers la vision par ordinateur, qui est une branche du domaine de l'intelligence artificielle. La segmentation s√©mantique permet de classer chaque pixel d'une image dans l'une des classes d√©finie en amont. La segmentation semantique peut utiliser toute sorte de classe, mais voici un exemple de r√©sultat qui nous interesse : ex.
J'AIMERAI PRECISER QU'avec uniquement de l'imagerie satellitaire, nous ne pourrons pas d√©cider du caract√®re habitable ou non d'un b√¢timent ni du nombre de logements √† l'int√©rieur. Par cons√©quent, nous ne pouvons pas remplacer l'enqu√™te cartographique, l'id√©e est d'aider les enqu√™teurs en mettant en valeur les zones avec le plus de b√¢timents √† visiter. 
:::

## Entra√Æner un mod√®le de segmentation

- [**Il faut**]{.orange} :
    - Une collection d'[**images satellites**]{.blue2} üõ∞Ô∏è
    - [**Des annotations**]{.blue2} üìç
- Le mod√®le apprend √† reproduire les annotations des images pour [**g√©n√©raliser**]{.orange} sur de nouvelles images  

::: notes

Pour entrainer un modele il faut deux choses : des images et des annotations.

- Une annotation est "la v√©rit√© attendue", comme par exemple l'image qui a √©t√© pr√©sent√©e √† la slide pr√©c√©dente

- Le mod√®le apprend √† reproduire les annotations des images pour [**g√©n√©raliser**]{.orange} sur de nouvelles images 
:::

## De la segmentation √† la d√©tection de changements

![](../img/strategy_segmentation.png){width=80%}

## Mod√®le utilis√©

- [**Architecture du mod√®le**]{.orange} üß†
    - [**SegFormer**]{.blue2} : un mod√®le l√©ger et performant
    - [**Transformers**]{.blue2} : [**m√©canismes d‚Äôattention**]{.green2} pour prendre en compte le contexte local et global
    - [**D√©codeur**]{.blue2} : Multi Layer Perceptron

- [**Adapt√©**]{.orange} √† nos donn√©es satellites


::: notes
Le mod√®le que nous avons s√©lectionn√© s‚Äôappuie sur une architecture appel√©e **SegFormer**.
Modele de segmentation d'image entrain√© par NVIDIA et opensource
Il a l'avantage d'etre tr√®s leger et donc rapide √† entrainer
Pour notre cas d'usage, c'est le modele qui a √©t√© le plus performant.

Il est bas√© sur une technologie appel√©e **Transformer**, connue pour ses performances dans de nombreux domaines de l‚Äôintelligence artificielle, notamment le traitement du langage, mais qui a aussi √©t√© adapt√©e √† l‚Äôimage. Ce n'est pas la plus r√©pendue en vision par ordinateur.

Un des atouts de cette architecture, ce sont les **m√©canismes d‚Äôattention**, qui permettent au mod√®le de prendre en compte le contexte local et global de l‚Äôimage. Pour le d√©codeur, c'est Multi Layer Perceptron classique.

Enfin, nous avons **ajust√© le mod√®le √† nos donn√©es** sp√©cifiques : des images satellites et des annotations.
:::


## √âvaluation

Pour √©valuer les performances du mod√®le entra√Æn√© :  
<div style="text-align: center;">
[**IOU**]{.orange} = Intersection Over Union  
</div>

![](../img/schemaIOU.png){width=80% fig-align="center"}

::: notes
Transition pour la suite : pour faire un entra√Ænement, il ne faut plus que des donn√©es...

L'IoU, ou *Intersection over Union*, est une mesure qu'on utilise pour √©valuer la qualit√© d‚Äôune pr√©diction en segmentation d‚Äôimage.

Concr√®tement, on compare deux zones :  
- celle que le mod√®le a pr√©dite comme appartenant √† une certaine classe,  
- et la zone r√©elle, qu‚Äôon appelle le *label de v√©rit√© terrain*.

On mesure alors **l‚Äôintersection** entre ces deux zones ‚Äì c‚Äôest la partie correctement pr√©dite ‚Äì  
et on la divise par **l‚Äôunion** des deux ‚Äì c‚Äôest-√†-dire l‚Äôensemble de tout ce qui a √©t√© soit pr√©dit, soit annot√©.

Un IoU de 1 signifie une correspondance parfaite.  
Un IoU de 0 signifie aucune correspondance.

Plus l‚ÄôIoU est √©lev√©, plus la pr√©diction est pr√©cise.  
C‚Äôest une m√©trique particuli√®rement adapt√©e pour des t√¢ches comme la n√¥tre, o√π on doit pr√©dire la forme exacte des b√¢timents ou des routes, pixel par pixel.
:::
