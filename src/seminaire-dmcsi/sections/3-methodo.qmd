## Segmentation sÃ©mantique

::: {layout-ncol=2}
![Pleiades Â© CNES_2023, Distribution AIRBUS DS](../img/pleiades_rennes.png){width=60% fig-align="center"}

![COSIA 2023](../img/segmentation.png){width=60% fig-align="center"}
:::

## EntraÃ®ner un modÃ¨le de segmentation

- ModÃ¨le entraÃ®nÃ© pour de la segmentation automatique [**depuis des exemples d'annotations**]{.orange}
- [**Il faut**]{.orange}:
    - Une collection d'[**images satellites**]{.blue2} ğŸ›°ï¸
    - [**Des annotations**]{.blue2} ğŸ“
- Model learns to reproduce annotations from images aiming to [**generalize**]{.orange} on new images ğŸ¯

## From segmentation to change detection

![](../img/strategy_segmentation.png){width=80%}

## Model used

- [**Model architecture**]{.orange} ğŸ§©:
    - [**Backbone**]{.blue2}: SegFormer ([**MiT**]{.green2})
    - [**Encoder**]{.blue2}: [**Transformer-based**]{.green2} (efficient self-attention, no positional encoding) âš™ï¸
    - [**Decoder**]{.blue2}: Lightweight [**MLP head**]{.green2} âœ¨

- [**Why SegFormer?**]{.orange} ğŸš€:
    - [**No complex decoders**]{.blue2} â†’ Efficient & scalable âš¡
    - [**Captures local & global context**]{.blue2} â†’ High accuracy ğŸ¯
    - [**No positional embeddings**]{.blue2} â†’ Improved resolution generalization ğŸ“

- [**Fine-tuned**]{.orange} on our dataset ğŸ—ƒï¸
