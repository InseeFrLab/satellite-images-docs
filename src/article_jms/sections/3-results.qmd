
## Entraînement et évaluation <!--  Raya -->

Les mosaïques d’images Pléiades et les annotations COSIA de Mayotte (2023), Martinique (2022) et Guadeloupe (2022) ont été utilisées pour l’entraînement du modèle. Des zones de test, ont été sélectionnées manuellement au sein de ces couples images annotations, pour représenter une diversité de contextes (quartiers résidentiels, bidonvilles, zones naturelles, centres urbains).  

Une image Pléiade telle qu'elle est livrée par l'IGN contient 2000\*2000 pixels. Elle est trop volumineuse pour être prise en entrée d’un réseau de neurones avec les capacités usuelles disponibles de mémoire vive du processeur graphique **GPU** (Graphics Processing Unit). Pour prévenir cela, l'ensemble des images des mosaïques sont découpées en plusieurs sous-images de 250\*250 pixels traitées indépendamment, appelées des tuiles.  

Comme un pixel sur une image Pléiades équivaut à 0.5\*0.5m², alors **un tuile a une superficie de 15 625m²**. La @fig-surface montre le nombre de tuiles par mosaïque envoyés pour l'entraînement mais également le nombre de tuiles gardés pour l'évaluation. Pour mieux comprendre ce que cela représente, la superficie associée est exprimée en km².

::: {#fig-surface .cell-output-display}
|     | train (**superficie km²**) | test (**superficie km²**) |
|:---------------------|:---------------------:|:--------------:|
| Guadeloupe  (2022)   |  >100 000 (**1 600**) | 1280 (**20**)  |
| Martinique  (2022)   |  >70 000 (**1 100**)  | 1230 (**19**)  |
| Mayotte     (2023)   |  23 000  (**357**)    |  840 (**13**)  |
:::

<!-- mc cp -r s3/projet-slums-detection/data-preprocessed/tuiles/COSIA/segmentation/PLEIADES/MARTINIQUE/2022/250/test/ .
cd 250/train/
ls -1 | wc -l 
-->

La fonction de perte (loss) utilisée est la **CrossEntropyWeighted**, avec un poids de 2 pour la classe bâtiment. Cette loss est une version pondérée de la CrossEntropy, qui permet de donner plus d’importance aux classes rares, comme les bâtiments, afin de compenser leur sous-représentation dans les données. En effet, sur un territoire, la surface de bâtiment est relativement faible comparé à la surface de verdure ou de sol nu.
 <!-- Remplacer "loss" par "fonction de perte" en précisant (loss) à la première occurrence ? --> 

La **CrossEntropyWeighted** pour un pixel i s’écrit :

$$
\text{CEWeighted}_i = - w_c \cdot \log(p_{i,c^*})
$$

avec :  
$$
\begin{align*}
- & \ c^* : \text{classe vraie du pixel } i, \\
- & \ p_{i,c^*} : \text{probabilité prédite pour cette classe}, \\
- & \ w_c : \text{poids associé à la classe}
\end{align*}
$$

La loss finale sur tous les pixels est la moyenne :

$$
\text{Loss} = \frac{1}{N} \sum_{i=1}^{N} \text{CEWeighted}_i
$$

Il est toutefois difficile de juger de l’efficacité de l’entraînement uniquement avec cette métrique.
Pour avoir une idée plus concrète des performances du modèle, une autre métrique, largement utilisée en segmentation d’images, a été implémentée: l’**Intersection Over Union** (IOU), représentée en @fig-iou.

![Présentation du calcul de l’IOU](../img/IOUschema.png){#fig-iou width=60%}

L’IOU se définit comme le rapport entre l’intersection des annotations et des prédictions et leur union. Plus l’IOU est proche de 1, plus les prédictions correspondent à la réalité. Dans la pratique, une IOU considérée comme très satisfaisante se situe autour de 0.6, car un certain décalage entre les annotations et les prédictions est inévitable. Néanmoins, cela n’empêche pas d’obtenir des prédictions fiables et qualitatives.

Pour notre modèle, l'IOU moyenne lors de l'entraînement se trouve autour de **0.81** pour l'ensemble des classes, et plus précisément de **0.84** pour la classe bâtiment. Dans les zones de test, on retrouve des IOU respectivement de **0.78** et **0.76**.

<!-- mettre texte pour expliquer les images  -->

La @fig-img-leg illustre une portion de zone de test issue de la mosaïque Mayotte 2023, avec en @fig-annot-pred la réalité terrain COSIA 2023 (gauche) et les prédictions produites par le modèle entraîné (droite).

![Zone de test Mayotte Pleiades © CNES_2023 et légende COSIA](../img/image_legende.png){#fig-img-leg width=80%}

![Couverture de sol COSIA 2023 VS prédictions](../img/annotations_vs_pred.png){#fig-annot-pred width=100%}


## Inférence 

Dans le cadre de notre projet de détection automatique des zones bâties à partir d’images satellites, il est essentiel de distinguer les phases d’entraînement du modèle et d’inférence. L’entraînement correspond à la phase exploratoire du projet, mobilisant des ressources matérielles conséquentes (notamment des GPU) et nécessitant de nombreux choix méthodologiques (prétraitement des images, ajustement des hyperparamètres, choix du modèle, etc.). Cette étape, une fois réalisée, n'est plus réellement centrale et peut être améliorée à la marge de manière indépendante. 

À l’inverse, la phase d’inférence s’apparente à une mise en production opérationnelle du modèle entraîné. Une fois les poids du modèle estimés, la génération de prédictions devient relativement peu coûteuse, notamment grâce à la possibilité d’exécuter les inférences sur CPU avec un temps de latence acceptable. L’enjeu devient alors de concevoir un dispositif fiable, reproductible et facilement mobilisable pour mettre à disposition les résultats du modèle, en particulier lorsque de nouvelles images satellites sont acquises.

Actuellement, les inférences sont réalisées, comme l'entraînement, sur des tuiles disjointes de taille $250 \times 250$ pixels. Cette découpage présente plusieurs inconvénients. Elle introduit des artefacts de bordure, limite la vision contextuelle du modèle, et empêche une prise en compte fluide des objets situés à la jonction de deux tuiles.

Afin d’améliorer la cohérence spatiale des prédictions, nous mettons en œuvre une stratégie d’inférence par fenêtre glissante (*sliding window*). Celle-ci consiste à réaliser plusieurs prédictions pour un même pixel, à partir de fenêtres décalées les unes par rapport aux autres. Les probabilités ainsi obtenues sont ensuite moyennées, ce qui permet de lisser les effets de bord, de renforcer la stabilité des contours et de réduire le bruit.

Cette inférence multiple est complétée par un pipeline de post-traitement multiclasse. Celui-ci repose d’abord sur une stratégie de repli contextuel : pour les pixels dont la probabilité maximale est inférieure à un certain seuil, la classe est réattribuée en fonction du voisinage local (via vote majoritaire ou moyenne pondérée des probabilités). Ensuite, des opérations de morphologie mathématique sont appliquées classe par classe afin de supprimer les artefacts et lisser les masques de segmentation. Enfin, un filtrage par taille minimale est mis en œuvre, avec des seuils spécifiques à chaque classe (par exemple, un bâtiment peut être plus petit qu’une zone d’eau). Ce traitement permet d’éliminer les objets aberrants ou trop petits pour être statistiquement significatifs.
<!-- jsp ou mettre ca mais on produit aussi les evolutions avec les constructions/destructions grace aux intersections d'anciennes pred -->

Afin d’industrialiser l’ensemble de la phase d’inférence, une API a été développée. Elle encapsule l’ensemble des étapes précédentes (inférence, post-traitement) et permet une exploitation simple et flexible du modèle par les différentes équipes concernées. Trois points d’entrée sont disponibles :

1. fourniture directe d’une image satellite à prédire,
2. sélection d’une zone géographique via coordonnées GPS (*bounding box*) et d'une année d’observation,
3. saisie d’un identifiant d’îlot (entité géographique infra-communale) et d'une année d'observation pour obtenir les prédictions correspondantes.

L’API intègre un mécanisme de cache qui évite de recalculer une prédiction déjà effectuée pour une même zone géographique, un même modèle et une même année. L’ensemble est déployé sur CPU et permet une chaîne de traitement entièrement automatisée, assurant une inférence rapide dès la réception de nouvelles images satellites.

Conçue comme un outil évolutif au service des équipes métiers de l’Insee, l’API est amenée à s’adapter aux besoins exprimés. Par exemple, à la suite d’un besoin identifié concernant le calcul de statistiques par îlot, une nouvelle fonctionnalité a été ajoutée pour retourner non seulement la carte de prédictions, mais aussi des indicateurs agrégés, tels que les surfaces de bâties par îlot.

Néanmoins, la diffusion de résultats via une API n’est pas toujours la modalité la plus adaptée aux usages internes. C’est pourquoi deux modes de restitution complémentaires ont été développés : d’une part, la production de fichiers Parquet contenant les résultats structurés pour exploitation statistique ; d’autre part, une application interactive cartographique, destinée aux agents de terrain. Cette application s’appuie sur un GeoServer <!-- def --> pour diffuser les images satellites, les cartes de segmentation, ainsi que les évolutions détectées (créations, destructions de bâti) <!-- les evolutions sont calculées en amont et stockées sur le geoserver au meme titre que les pred -->, facilitant ainsi le croisement avec les informations d’enquête et les validations sur le terrain.

![Schéma de la pipeline](../img/app-architecture.png){#fig-pipeline width=75%}

## Mise à disposition pour les statisticiens <!-- Thomas -->

### Vers de nouveaux indicateurs statistiques ? {#sec-indic_stats}

Contrairement à d’autres applications de l’apprentissage automatique déjà déployées à l’Insee, comme les modèles de classification de textes pour la codification automatique dans des nomenclatures, les sorties brutes d’un modèle de segmentation d’images ne constituent pas, en soi, des données statistiques directement exploitables ou diffusables. Une carte de segmentation s’apparente davantage à un support intermédiaire, qui doit faire l’objet d’une interprétation, d’un traitement spatial et d’une contextualisation pour devenir une information statistique pertinente.
Comme le souligne le Mémorandum de Varsovie, ces nouvelles formes de données issues de sources non traditionnelles peuvent cependant jouer un rôle essentiel : elles peuvent soit conduire à la construction de nouveaux indicateurs, soit servir de proxies statistiques utiles pour améliorer la qualité ou la finesse d’indicateurs existants.
En ce sens, le développement d’un modèle de segmentation performant n’a de valeur, dans le contexte de la statistique publique, que s’il permet effectivement de produire de l’information utile, fiable, et intégrable dans les systèmes d’observation existants. À défaut, l’usage d’un tel outil par les statisticiens resterait discutable, car sans finalité opérationnelle claire.

À ce stade du projet, l’enjeu est donc de déterminer les indicateurs statistiques pouvant être dérivés des sorties du modèle. Cette démarche doit reposer sur une co-construction entre les équipes métiers de l’Insee, qui expriment les besoins statistiques concrets, et la DMGC, appuyée par le SSP Lab, qui assure l’évaluation de la faisabilité technique, la pertinence méthodologique, et le développement des outils associés.
<!-- Expliquer ou détailler ces abréviations ? -->

Plusieurs cas d’usage ont d’ores et déjà été identifiés. L’un d'eux, détaillé en @sec-use_case, concerne la construction d’indicateurs d’évolution du bâti. Étant donné que le modèle attribue une classe à chaque pixel, et que chaque pixel représente une surface de $0,25 m^2$, il est possible de calculer la surface bâtie dans une zone géographique donnée à une date donnée. En comparant ces surfaces sur plusieurs dates, on peut alors quantifier les dynamiques de construction ou de disparition de bâtiments. Croisées avec d’autres sources de données, comme le Répertoire d’immeubles Localisés (RIL), ces surfaces bâties peuvent fournir des proxies de l’évolution du parc de logements et, par extension, de la population. De telles approches ouvrent des perspectives intéressantes pour l’enrichissement des dispositifs de suivi, en particulier dans les zones où les données administratives sont lacunaires ou peu à jour comme c'est le cas dans certains DROM.

Concrètement, nous avons produit des fichiers millésimés pour chacun des DROM, retraçant l’évolution de la surface bâtie par îlot, pour chaque année disponible. Cette base de données constitue une ressource structurée et directement exploitable pour des analyses statistiques, déjà mobilisée par la DMTR pour évaluer la qualité de l'enquête cartographique. Ces premiers résultats illustrent le potentiel d’une telle approche pour renforcer la couverture, la réactivité et la granularité des indicateurs mobilisés dans les travaux de la statistique publique territorialisée.
<!-- Expliquer ou détailler l'abréviation DMTR ? -->


### Une application interactive pour les agents de terrain

Si les résultats agrégés issus du modèle de segmentation, notamment les bases d’évolution des surfaces bâties, trouvent des applications dans les analyses post-enquête cartographique, l’appui à la production des chiffres du recensement ou encore l’évaluation de politiques publiques comme l'objectif Zéro Artificialisation Nette (ZAN), un autre besoin a rapidement émergé du terrain. Les agents en charge de l’organisation des enquêtes cartographiques ont exprimé le besoin de pouvoir anticiper la charge de travail que représente une zone, notamment dans les territoires où l’habitat précaire est très dynamique. Dans ces zones, les évolutions rapides du bâti peuvent rendre les opérations d’enquête particulièrement complexes à planifier et à gérer.
Plus précisément, ces agents souhaitent pouvoir visualiser les changements intervenus entre deux campagnes d’enquête, afin d’identifier les secteurs à forte évolution et de prioriser efficacement les ressources. Ils ont ainsi besoin d’un outil leur permettant une lecture intuitive et rapide des transformations spatiales, en amont du travail de terrain.

Pour répondre à ces attentes, une application web interactive a été développée. Son objectif principal est de rendre accessibles, de manière simple et ergonomique, les résultats issus du modèle de segmentation aux agents de terrain. L’application permet de visualiser l’ensemble des images satellite disponibles pour les différents départements d’outre-mer (Guadeloupe, Martinique, Guyane, La Réunion, Mayotte), selon différents millésimes. Les utilisateurs peuvent ainsi comparer les images entre deux années données afin d’identifier visuellement les évolutions notables.
Au-delà de la simple visualisation des images, l’application intègre également les cartes de segmentation générées par le modèle. Ces cartes fournissent une lecture globale et à grande échelle de la répartition des classes (bâti, végétation, etc.). Afin d’optimiser la détection des évolutions, des masques de changement ont été calculés entre deux années à partir des cartes de segmentation. Ces masques mettent en évidence les zones de création ou de transformation du bâti, facilitant ainsi l’identification des secteurs à fort changement.

![Application web, statistiques sur le bâti (Mayotte 2017/2018)](../img/cratt_stat.png){#fig-cratt-stat width=75%}

![Application web, visualisation des prédictions (Mayotte 2017)](../img/cratt_carte.png){#fig-cratt-carte width=75%}

<!-- Mettre une capture de l'appli -->

L’application intègre également des indicateurs statistiques directement liées aux îlots. L'application contient les délimitations des îlots, et l’utilisateur peut accéder aux statistiques associées en cliquant sur un îlot spécifique. Une table de synthèse recense l’ensemble des statistiques disponibles pour tous les îlots, avec la possibilité d’effectuer des recherches ciblées. Il est ainsi possible de rechercher un îlot par son identifiant, d’accéder à ses données et de recentrer automatiquement la carte. Les statistiques de surface, présentées en @sec-indic_stats, sont ainsi pleinement exploitables dans l’outil. L’application est accessible en ligne à l’adresse suivante : [https://inseefrlab.github.io/satellite-images-webapp/]().

L’application a été conçue comme un outil modulaire, destiné à évoluer en fonction des besoins exprimés par les utilisateurs. Toute remontée de terrain est prise en compte pour améliorer son ergonomie et ses fonctionnalités. L’objectif est de construire un outil aligné sur les usages opérationnels des enquêtes cartographiques dans les DROM.

L’un des enjeux majeurs de cette approche reste la qualité des données d’entrée. La rapidité d’acquisition des images ainsi que leur qualité (notamment l’absence de nuages) sont des conditions indispensables à l'utilité et la fiabilité des résultats. De ce point de vue, un partenariat renforcé avec l’Institut national de l'information géographique et forestière (IGN) apparaît comme indispensable. L’IGN dispose à la fois des expertises nécessaires en prétraitement d’images satellite et de ressources pour garantir un flux de données pertinent pour les usages statistiques.
