
## Entraînement et évaluation <!--  Raya -->

- IOU, Loss, zone de test manuel (calculer la taille des zones de test)

Metriques et images



## Inférence 

Dans le cadre de notre projet de détection automatique des zones bâties à partir d’images satellites, il est essentiel de distinguer les phases d’entraînement du modèle et d’inférence. L’entraînement correspond à la phase exploratoire du projet, mobilisant des ressources matérielles conséquentes (notamment des GPU) et nécessitant de nombreux choix méthodologiques (prétraitement des images, ajustement des hyperparamètres, choix du modèle, etc.). Cette étape, une fois réalisée, n'est plus réellement centrale et peut être amélioré à la marge de manière indépendante. 

À l’inverse, la phase d’inférence s’apparente à une mise en production opérationnelle du modèle entraîné. Une fois les poids du modèle estimés, la génération de prédictions devient relativement peu coûteuse, notamment grâce à la possibilité d’exécuter les inférences sur CPU avec un temps de latence acceptable. L’enjeu devient alors de concevoir un dispositif fiable, reproductible et facilement mobilisable pour mettre à disposition les résultats du modèle, en particulier lorsque de nouvelles images satellites sont acquises.

Actuellement, les inférences sont réalisées sur des tuiles disjointes de taille $250 \times 250$ pixels, qui correspondent à la taille utilisée lors de l’entraînement. Chaque image satellite de $2000 \times 2000$ pixels est ainsi découpée en 64 sous-images traitées indépendamment. Cette stratégie, bien que simple, présente plusieurs inconvénients. Elle introduit des artefacts de bordure, limite la vision contextuelle du modèle, et empêche une prise en compte fluide des objets situés à la jonction de deux tuiles.

Afin d’améliorer la cohérence spatiale des prédictions, nous mettons en œuvre une stratégie d’inférence par fenêtre glissante (*sliding window*). Celle-ci consiste à réaliser plusieurs prédictions pour un même pixel, à partir de fenêtres décalées les unes par rapport aux autres. Les probabilités ainsi obtenues sont ensuite moyennées, ce qui permet de lisser les effets de bord, de renforcer la stabilité des contours et de réduire le bruit.

Cette inférence multiple est complétée par un pipeline de post-traitement multiclasse. Celui-ci repose d’abord sur une stratégie de repli contextuel : pour les pixels dont la probabilité maximale est inférieure à un certain seuil, la classe est réattribuée en fonction du voisinage local (via vote majoritaire ou moyenne pondérée des probabilités). Ensuite, des opérations de morphologie mathématique sont appliquées classe par classe afin de supprimer les artefacts et lisser les masques de segmentation. Enfin, un filtrage par taille minimale est mis en œuvre, avec des seuils spécifiques à chaque classe (par exemple, un bâtiment peut être plus petit qu’une zone d’eau). Ce traitement permet d’éliminer les objets aberrants ou trop petits pour être statistiquement significatifs.

Afin d’industrialiser l’ensemble de la phase d’inférence, une API a été développée. Elle encapsule l’ensemble des étapes précédentes (inférence, post-traitement) et permet une exploitation simple et flexible du modèle par les différentes équipes concernées. Trois points d’entrée sont disponibles :

- fourniture directe d’une image satellite à prédire,
- sélection d’une zone géographique via coordonnées GPS (bounding box) et année d’observation,
- saisie d’un identifiant d’îlot (entité géographique infra-communale) pour obtenir les prédictions correspondantes.

L’API intègre un mécanisme de cache qui évite de recalculer une prédiction déjà effectuée pour une même zone géographique et un même modèle. L’ensemble est déployé sur CPU et permet une chaîne de traitement entièrement automatisée, assurant une inférence rapide dès la réception de nouvelles images satellites.

Conçue comme un outil évolutif au service des équipes métiers de l’Insee, l’API est amenée à s’adapter aux besoins exprimés. Par exemple, à la suite d’un besoin identifié concernant le calcul de statistiques par îlot, une nouvelle fonctionnalité a été ajoutée pour retourner non seulement la carte de prédictions, mais aussi des indicateurs agrégés, tels que les surfaces de bâties par îlot.

Néanmoins, la diffusion de résultats via une API n’est pas toujours la modalité la plus adaptée aux usages internes. C’est pourquoi deux modes de restitution complémentaires ont été développés : d’une part, la production de fichiers Parquet contenant les résultats structurés pour exploitation statistique ; d’autre part, une application interactive cartographique, destinée aux agents de terrain. Cette application s’appuie sur un GeoServer pour diffuser les images satellites, les cartes de segmentation, ainsi que les évolutions détectées (créations, destructions de bâti), facilitant ainsi le croisement avec les informations d’enquête et les validations sur le terrain.

## Mise à disposition pour les statisticiens <!-- Thomas -->

### Vers de nouveaux indicateurs statistiques ?

- Le développement d’un modèle performant n’a de valeur que s’il permet de produire des informations utiles pour la statistique publique.
- L’enjeu est désormais d’identifier quels indicateurs pertinents et exploitables peuvent être dérivés à partir des prédictions du modèle. Partenariat avec des équipes de l'insee
- Des fichiers au format Parquet ont été générés pour tracer l’évolution du bâti dans le temps, constituant une première base exploitable pour des analyses statistiques. Recensement

### Une application interactive pour les agents de terrain

- Une application web interactive a été développée pour permettre une consultation directe des résultats
- Cette application s’appuie sur un GeoServer qui héberge et diffuse les images satellites et les cartes de segmentation associées.
- Elle offre une interface cartographique permettant aux agents de l’Insee en charge des enquêtes de terrain :

  - d’accéder aux images avant/après sur une zone donnée,
  - de visualiser les détections de destructions et de créations de bâtiments,
  - et ainsi de mieux préparer les opérations de terrain ou de **vérifier des résultats étranges post collecte.


Dans tous les cas l'enjeu c'est les données. Plus tot on a accès à des données le mieux c'est => partenariat avec l'IGN indispensable


![Schéma de la pipeline](../img/app-architecture.png){#fig-pipeline width=75%}
