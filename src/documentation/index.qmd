---
format:
  html:
    header-includes: |
        <link rel="icon" type="image/png" sizes="32x32" href="../_extensions/InseeFrLab/onyxia/favicon-32x32.png">
---

# ğŸ“¦ Structure du projet

Ce projet structurÃ© en **7 dÃ©pÃ´ts Git** open source, hÃ©bergÃ©s sur GitHub, et organisÃ©s au sein de lâ€™Ã©quipe [Satellite images](https://github.com/orgs/InseeFrLab/teams/satellite-images) de lâ€™organisation *InseeFrLab*.

## ğŸ“ Les diffÃ©rents dÃ©pÃ´ts

### 1ï¸âƒ£ Astrovision : Package utilitaire pour le traitement dâ€™images satellites

Pour manipuler des donnÃ©es gÃ©ospatiales, la bibliothÃ¨que incontournable est [GDAL](https://gdal.org/en/stable/). Afin de faciliter son usage en Python, des wrappers comme [Rasterio](https://rasterio.readthedocs.io/en/stable/intro.html) sont couramment utilisÃ©s. Rasterio offre une interface efficace pour travailler avec des donnÃ©es *raster*.

Dans notre projet, nous avons dÃ©veloppÃ© un package complÃ©mentaire, [Astrovision](https://github.com/InseeFrLab/astrovision), qui centralise un ensemble de fonctions utilitaires : dÃ©coupage dâ€™images, gestion des mÃ©tadonnÃ©es, visualisation, etc. Ce package nâ€™est pas strictement indispensable, cela a Ã©tÃ© aussi pour nous d'apprendre Ã  dÃ©ployer un package python. Le projet pourrait fonctionner en sâ€™appuyant exclusivement sur Rasterio, avec quelques adaptations.


### 2ï¸âƒ£ PrÃ©paration des images satellites

Le dÃ©pÃ´t [satellite-images-preprocess](https://github.com/InseeFrLab/satellite-images-preprocess) regroupe les fonctions nÃ©cessaires Ã  la prÃ©paration des images avant l'entraÃ®nement des modÃ¨les. Ce dÃ©pÃ´t nâ€™est utilisÃ© **quâ€™en amont d'un entraÃ®nement**, et n'est donc pas utile lorsque l'on souhaite simplement rÃ©aliser de l'infÃ©rence sur de nouvelles images.

Le *pipeline* de preprocessing comprend les Ã©tapes suivantes :

1. GÃ©nÃ©ration automatique des *labels* Ã  partir dâ€™un jeu dâ€™annotations.
2. DÃ©coupage des images sources en tuiles plus petites (pour Ã©viter les problÃ¨mes de mÃ©moire lors de l'entraÃ®nement).
3. Suppression des images contenant des nuages.
4. Filtrage des images selon une rÃ©gion dâ€™intÃ©rÃªt dÃ©finie.
5. Calcul des moyennes et Ã©carts types des bandes spectrales pour la normalisation.
6. RÃ©alisation du split *train/test* et sauvegarde des donnÃ©es sur un bucket S3.

::: {.callout-note}
Le choix de sÃ©parer ce dÃ©pÃ´t de celui de l'entraÃ®nement est discutable, mais repose sur plusieurs objectifs :

- Isoler les diffÃ©rentes Ã©tapes du pipeline.
- Ã‰viter de rÃ©-exÃ©cuter inutilement le preprocessing Ã  chaque entraÃ®nement.
- Faciliter la modularitÃ© du projet.
Ces objectifs ne sont pas forcÃ©ment en contradiction avec le fait de tout centraliser dans un seul package.
:::


### 3ï¸âƒ£ EntraÃ®nement des modÃ¨les

L'entraÃ®nement est gÃ©rÃ© par le dÃ©pÃ´t [satellite-images-train](https://github.com/InseeFrLab/satellite-images-train). Il est nÃ©cessaire d'avoir Ã  disposition des images dÃ©jÃ  prÃ©traitÃ©es et stockÃ©es sur le S3, ce qui peut Ãªtre fait via le dÃ©pÃ´t de preprocessing.

Lâ€™objectif de ce dÃ©pÃ´t est dâ€™offrir un environnement modulaire permettant dâ€™expÃ©rimenter diffÃ©rentes stratÃ©gies dâ€™entraÃ®nement et dâ€™optimiser les hyperparamÃ¨tres propre Ã  l'entraÃ®nement (et rien d'autres !). Tous les rÃ©sultats sont logguÃ©s via [MLFlow](https://projet-slums-detection-mlflow.user.lab.sspcloud.fr/).

Deux familles de modÃ¨les de segmentation sont actuellement intÃ©grÃ©es :

- [DeepLabv3](https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/) (et sa variante binaire).
- [Segformer](https://github.com/NVlabs/SegFormer), de **b0 Ã  b5**.

CÃ´tÃ© fonctions de perte, plusieurs variantes de l'entropie croisÃ©e sont disponibles (classique, pondÃ©rÃ©e, binaire, etc.).


### 4ï¸âƒ£ InfÃ©rence Ã  partir de nouvelles images

Le dÃ©pÃ´t [satellite-images-inference](https://github.com/InseeFrLab/satellite-images-inference) est dÃ©diÃ© Ã  lâ€™infÃ©rence. C'est peut Ãªtre le dÃ©pÃ´t le moins "isolÃ©" dans le sens oÃ¹ il contient Ã  la fois les codes de l'API qui est utilisÃ©e pour rÃ©aliser l'infÃ©rence mais Ã©galement divers scripts nÃ©cessaires que cela soit pour l'infÃ©rence, le post-processing ou bien la reception de nouvelles images Ã  infÃ©rer.

Lâ€™**API**, dÃ©veloppÃ©e avec **FastAPI**, est dÃ©ployÃ©e sur **SSPCloud**. Elle propose trois *endpoints* principaux :

1. `GET /predict_image` â€” PrÃ©diction dâ€™une image individuelle stockÃ©e sur S3.
2. `GET /predict_cluster` â€” PrÃ©diction sur un Ã®lot identifiÃ© par son code (peut inclure plusieurs images).
3. `GET /predict_bbox` â€” PrÃ©diction sur une *bounding box* dÃ©finie par des coordonnÃ©es GPS (peut inclure plusieurs images).

Un systÃ¨me de **cache** est en place pour Ã©viter les redondances de calcul sur une mÃªme image.


::: {.callout-important}
# âš ï¸ **Limites actuelles de lâ€™API :**

- Les prÃ©dictions en batch ne sont pas possibles directement (elles doivent Ãªtre sÃ©quentielles) puisque seuls des *endpoints* `GET` sont disponibles.
- Certaines opÃ©rations pourraient Ãªtre asynchrones pour amÃ©liorer les performances.
- L'API reproduit le preprocessing, idÃ©alement, il faudrait `wrapper` tout dans un modÃ¨le MLFlow et donc crÃ©er une custom class lors de l'entrainement.
:::


### 5ï¸âƒ£ Application CRaTT

Le code de l'application CRaTT permettant de visualiser les rÃ©sultats sur des territoires entier est disponible dans le dÃ©pÃ´t [satellite-images-webapp](https://github.com/inseeFrLab/satellite-images-webapp). L'application est construite avec [Observable Framework](https://observablehq.com/framework/) qui permet de dÃ©ployer sur un site statique tout en gardant un certain niveau dâ€™interactivitÃ© dans les visualisations que l'on peut montrer. La manipulation des donnÃ©es peut se faire dans le langage de notre choix (Python, R, SQL, etc.) et les visualisation se font en JavaScript.

Le dÃ©ploiement est rÃ©alisÃ© via Github Pages et est accessible Ã  l'adresse suivante : [https://inseefrlab.github.io/satellite-images-webapp/]().


### 6ï¸âƒ£ DÃ©ploiement des applications

Pour gÃ©rer les diffÃ©rents dÃ©ploiements de l'ensemble du projet, nous avons crÃ©er un dÃ©pÃ´t GitOps. Il s'agit du dÃ©pÃ´t [satellite-images-cd](https://github.com/inseeFrLab/satellite-images-cd).
Il contient les *manifests* Kubernetes des services dÃ©ployÃ©s ainsi que les templates d'ArgoCD afin d'avoir un dÃ©ploiement continu.

En avril 2025, 2 services sont dÃ©ployÃ©s :

- l'API d'infÃ©rence
- le Geoserver pour la mise Ã  disposition des tuiles d'images

### 7ï¸âƒ£ Documentation du projet

La documentation que vous lisez actuellement est rÃ©aliser avec Quarto et toute contribution est la bienvenue dans le dÃ©pÃ´t [satellite-images-docs](https://github.com/inseeFrLab/satellite-images-docs).


## Le projet sur le Datalab -- SSPCloud

### Le namespace

Afin de pouvoir contribuer au projet il est nÃ©cessaire d'avoir accÃ¨s au namespace `projet-slums-detection`. Pour cela, vous pouvez contacter la Diit. 

### Les donnÃ©es

Le S3 associÃ© au projet est structurÃ© en plusieurs dossiers. 


#### ğŸ“ **data-raw**

Ce dossier contient les images satellites telles qu'on les reÃ§oit sans modification. Seules les donnÃ©es de la Guyane et de Saint-Martin sont un peu diffÃ©rentes avec des sous dossiers `brut` car elles ont nÃ©cessitÃ© des ajustements prÃ©alables. En effet, pour tous les autres dÃ©partements les donnÃ©es proviennent de l'IGN qui nous transmets les mosaÃ¯ques d'images 2000x2000.

La structure du dossier est : 

`data-raw/<SOURCE>/<DEPARTEMENT>/<ANNEE>/*.tif`

#### ğŸ“ **data-label**

Ce dossier contient les donnÃ©es gÃ©ographiques contenant les labels que nous utilisons lors de notre entraÃ®nement et que nous considÃ©rons donc comme **vraie valeur**. En fonction de la source de l'annotation le format des fichiers peut diffÃ©rer. Pour le moment, 2 sources de donnÃ©es sont utilisÃ©es il s'agit de la [BDTOPO](https://geoservices.ign.fr/bdtopo) et de [COSIA](https://cosia.ign.fr/) et les donnÃ©es sont stockÃ©es respectivement au format Shapefile et au format Geopackage.

La structure du dossier est : 

```
data-label/
â”œâ”€â”€ BDTOPO/
â”‚   â”œâ”€â”€ bdtopo-id2label.json
â”‚   â””â”€â”€ <DEPARTEMENT>/
â”‚       â””â”€â”€ <ANNEE>/
â”œâ”€â”€ COSIA/
â”‚   â”œâ”€â”€ cosia-id2label.json
â”‚   â””â”€â”€ <DEPARTEMENT>/
â”‚       â””â”€â”€ <ANNEE>/
```

#### ğŸ“ **data-preprocessed**

Le dossier `data-preprocessed/` contient l'ensemble des donnÃ©es prÃ©parÃ©es pour l'entraÃ®nement d'un modÃ¨le. Il est organisÃ© en deux sous-dossiers principaux, le dossier `labels/` qui contient les fichiers d'Ã©tiquettes (`.npy`) associÃ©s Ã  chaque tuile d'image ainsi que le dossier `patchs/` contient les images (`.jp2`) associÃ©es portant le mÃªme nom.

La structure du dossier est donc : 

```
data-preprocessed/
â”œâ”€â”€ labels/                        # Ã‰tiquettes
â”‚   â””â”€â”€ <LABELER>/                 # Annotateur (ex: COSIA, BDTOPO...)
â”‚       â””â”€â”€ <TASK>/                # TÃ¢che spÃ©cifique (ex: segmentation, classification...)
â”‚           â””â”€â”€ <SOURCE>/          # Source de donnÃ©es (ex: PLEIADES, SENTINEL...)
â”‚               â””â”€â”€ <DEPARTEMENT>/ # DÃ©partement (ex: MAYOTTE, REUNION...)
â”‚                   â””â”€â”€ <ANNEE>/   # AnnÃ©e de la donnÃ©e (ex: 2023)
â”‚                       â””â”€â”€ <TILE-SIZE>/  # Taille des tuiles (ex: 125, 250...)
â”‚                           â”œâ”€â”€ train/    # Jeu d'entraÃ®nement
â”‚                           â”‚   â””â”€â”€ *.npy # Fichiers numpy
â”‚                           â””â”€â”€ test/     # Jeu de test
â”‚                               â””â”€â”€ *.npy # Fichiers numpy
â”œâ”€â”€ patchs/                        # Images
â”‚   â””â”€â”€ <LABELER>/                 # Annotateur (ex: COSIA, BDTOPO...)
â”‚       â””â”€â”€ <TASK>/                # TÃ¢che spÃ©cifique (ex: segmentation, classification...)
â”‚           â””â”€â”€ <SOURCE>/          # Source de donnÃ©es (ex: PLEIADES, SENTINEL...)
â”‚               â””â”€â”€ <DEPARTEMENT>/ # DÃ©partement (ex: MAYOTTE, REUNION...)
â”‚                   â””â”€â”€ <ANNEE>/   # AnnÃ©e de la donnÃ©e (ex: 2023)
â”‚                       â””â”€â”€ <TILE-SIZE>/  # Taille des tuiles (ex: 125, 250...)
â”‚                           â”œâ”€â”€ train/    # Jeu d'entraÃ®nement
â”‚                           â”‚   â””â”€â”€ *.jp2 # Fichiers images jp2
â”‚                           â””â”€â”€ test/     # Jeu de test
â”‚                               â””â”€â”€ *.jp2 # Fichiers images jp2

```



#### ğŸ“ **data-prediction**

Le dossier `data-prediction/`regroupe les rÃ©sultats de prÃ©dictions gÃ©nÃ©rÃ©es par diffÃ©rents modÃ¨les. Les prÃ©dictions sont disponibles au format Parquet mais Ã©galement au format GeoPackage pour pouvoir les utiliser dans le Geoserver.

La structure du dossier est : 

```
data-prediction/
â””â”€â”€ <SOURCE>/                  # Source de donnÃ©es (ex: PLEIADES, SENTINEL...)
    â””â”€â”€ <DEPARTEMENT>/          # DÃ©partement (ex: MAYOTTE, REUNION...)
        â””â”€â”€ <ANNEE>/            # AnnÃ©e de la donnÃ©e (ex: 2023)
            â””â”€â”€ <MODEL-NAME>/   # Nom du modÃ¨le utilisÃ© pour la prÃ©diction
                â””â”€â”€ <MODEL-VERSION>/ # Version du modÃ¨le (ex: 1, 2...)
                    â”œâ”€â”€ *.parquet    # Fichiers de prÃ©diction au format parquet
                    â””â”€â”€ *.gpkg       # Fichiers de prÃ©diction au format GeoPackage
```

#### ğŸ“ **cache-predictions**

Le dossier `cache-predictions/` contient les logits intermÃ©diaires produits par les modÃ¨les lors du processus de prÃ©diction afin de ne pas refaire une prÃ©diction qui aurait dÃ©jÃ  Ã©tÃ© rÃ©alisÃ©e.
L'organisation du dossier reprend la mÃªme hiÃ©rarchie que `data-prediction` :

```
cache-predictions/
â””â”€â”€ <SOURCE>/                  # Source de donnÃ©es (ex: PLEIADES, SENTINEL...)
    â””â”€â”€ <DEPARTEMENT>/          # DÃ©partement (ex: MAYOTTE, REUNION...)
        â””â”€â”€ <ANNEE>/            # AnnÃ©e de la donnÃ©e (ex: 2023)
            â””â”€â”€ <MODEL-NAME>/   # Nom du modÃ¨le utilisÃ© pour la prÃ©diction
                â””â”€â”€ <MODEL-VERSION>/ # Version du modÃ¨le (ex: 1, 2...)
                    â””â”€â”€ *.npy       # Logits prÃ©dits
```

#### ğŸ“ **data-roi**

Le dossier `data-roi` contient les contours gÃ©ographique de chaque dÃ©partement afin de pouvoir filtrer les images efficacement que ce soit lors de l'Ã©tape de preprocessing que lors de l'Ã©tape de l'infÃ©rence. Les contours sont Ã  la fois stockÃ©s en parquet et en geojson (un seul des deux formats pourrait suffire).  

Ces donnÃ©es ont Ã©tÃ© construites Ã  la main Ã  partir de donnÃ©es officielles. Les contours des territoires n'Ã©tant pas sensÃ©s changer, il n'y a pas Ã  mettre Ã  jour ces donnÃ©es.  

La structure du dossier est : 

```
data-roi/
â”œâ”€â”€ <DEPARTEMENT>.parquet
â””â”€â”€ <DEPARTEMENT>.geojson
```

#### ğŸ“ **cluster-geom-raw**

Le dossier `cluster-geom-raw` contient tout l'historique des gÃ©omÃ©tries d'Ã®lots non preprocessÃ©.  

La gÃ©omÃ©trie des Ã®lots est arrÃªtÃ©e chaque annÃ©e au 31 octobre ; câ€™est cette version qui s'applique pendant le recensement de la population (RP).  
Par exemple, pour lâ€™enquÃªte annuelle de recensement 2026, il faudra utiliser la gÃ©omÃ©trie des Ã®lots arrÃªtÃ©e au 31 octobre 2025.  

Dans tous les cas, il est indispensable de s'assurer que le SERN GÃ©ographie et le ST Mayotte disposent bien des mÃªmes rÃ©fÃ©rentiels dâ€™Ã®lots. Des ajustements exceptionnels pourraient Ãªtre nÃ©cessaires compte tenu de l'urgence post-Chido.

Une fois le fichier avec les derniÃ¨res gÃ©omÃ©tries traitÃ©, les nouveaux fichiers parquet sont disponibles dans **data-clusters**.

#### ğŸ“ **data-clusters**

Le dossier `data-clusters` contient les contours gÃ©ographique de chaque Ã®lot pour les diffÃ©rents dÃ©partements. Ces informations sont nÃ©cessaires lors de l'infÃ©rence pour un Ã®lot donnÃ© ainsi que pour le dÃ©ploiement de la webapp qui permet de rÃ©aliser des statistiques par Ã®lot. Le dossier est simplement un fichier parquet partitionnÃ© : 

```
data-clusters/
â”œâ”€â”€ dep=<DEPARTEMENT>/
      â””â”€â”€ part-0.parquet
```


### Les services

Le projet utilise plusieurs service au sein du datalab.

-
#### MLFlow

MLflow est utilisÃ© lors de la phase d'entraÃ®nement pour *tracker* et optimiser nos modÃ¨les.
Il permet de *logguer* les hyperparamÃ¨tres, les mÃ©triques et les artefacts gÃ©nÃ©rÃ©s au cours des expÃ©rimentations. MLflow joue Ã©galement le rÃ´le de *Model Registry*, dans lequel Ã  chaque modÃ¨le est associÃ© un tag  tel que *staging*, *production* ou *archived*. Cela facilite le versionnement et la bonne gestion du cycle de vie des modÃ¨les dans le temps

-
#### ArgoCD

ArgoCD est dÃ©ployÃ© pour superviser et gÃ©rer automatiquement les applications prÃ©sentes dans notre namespace. Il permet de surveiller en permanence l'Ã©tat de dÃ©ploiement des applications et dÃ©tecte automatiquement toute modification des manifests dans le dÃ©pÃ´t GitOps dÃ©diÃ© ([https://github.com/inseeFrLab/satellite-images-cd]()). Lorsqu'une modification est dÃ©tectÃ©e, ArgoCD applique automatiquement les changements sur le cluster, garantissant une parfaite synchronisation entre le code source et l'Ã©tat effectif des dÃ©ploiements.

-
#### Argo Workflows

Argo Workflows est utilisÃ© pour orchestrer l'exÃ©cution parallÃ¨le de scripts, ce qui optimise considÃ©rablement les temps de calcul. Les workflows sont dÃ©crits dans des fichiers YAML stockÃ©s dans les rÃ©pertoires `argo-workflows/` prÃ©sents dans les diffÃ©rents dÃ©pÃ´ts.
Argo Workflows est sollicitÃ© Ã  diffÃ©rents stades du projet, notamment pour exÃ©cuter les Ã©tapes de preprocessing des donnÃ©es, l'entraÃ®nement de modÃ¨les en parallÃ¨le, ainsi que l'infÃ©rence Ã  grande Ã©chelle.

-
#### Geoserver

GeoServer permet la publication et la mise Ã  disposition de donnÃ©es gÃ©ographiques sous forme de flux normalisÃ©s (WMS, WFS, WCS). Contrairement aux autres services mentionnÃ©s, GeoServer n'est pas directement provisionnÃ© par le Datalab, ni dÃ©ployÃ© via Helm Chart.

Ã€ ce jour, GeoServer ne peut pas accÃ©der directement aux fichiers stockÃ©s sur un stockage objet type S3. En consÃ©quence, toutes les images ou donnÃ©es que nous souhaitons exposer doivent Ãªtre dupliquÃ©es dans un PVC associÃ© au pod GeoServer...