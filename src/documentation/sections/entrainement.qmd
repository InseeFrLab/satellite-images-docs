# EntraÃ®nement d'un modÃ¨le 

Lien vers le dÃ©pÃ´t d'entraiement : [https://github.com/InseeFrLab/satellite-images-train]().

## ğŸš€ DÃ©marrage rapide

### 1. Cloner et configurer l'environnement

```bash
git clone https://github.com/InseeFrLab/satellite-images-train.git
cd satellite-images-train
uv sync
uv run pre-commit install
```

### 2. Lancer en local

DÃ©finissez les paramÃ¨tres d'entraÃ®nement puis exÃ©cutez :

```bash
bash bash/mlflow-run.sh
```

L'ensemble de l'exÃ©cution sera automatiquement enregistrÃ© dans MLflow.


### 3. Lancer avec Argo Workflows â˜ï¸

1. Mettez Ã  jour les paramÃ¨tres dans argo-workflows/train-workflow.yaml `argo-workflows/train-workflow.yaml`.
2. Soumettez le workflow via l'interface CLI ou l'interface graphique Argo en copier/collant le template:

```bash
argo submit argo-workflows/train-workflow.yaml
```

## ğŸ§  Configuration du modÃ¨le

Le pipeline d'entraÃ®nement est construit avec PyTorch et conÃ§u pour Ãªtre flexible :

- **Architectures** : `deeplabv3`, `segformer-b[0â€“5]`, `single_class_deeplabv3`
- **Fonctions de perte**: Cross-Entropy (avec diffÃ©rentes variantes), BCE, BCE avec logits
- **Schedulers**: `reduce_on_plateau`, `one_cycle`, etc.
- **Sources des labels**: `BDTOPO`, `COSIA` ou autres.

De nouveaux modÃ¨les peuvent Ãªtre implÃ©menter en rajoutant le code dans `src/models/components/segmentation_models.py`.
Les fonctions de perte sont dÃ©finies dans `src/config/loss.py` et les schedulers dans `src/config/scheduling.py`.
En ce qui concerne les annotations, cela se joue dans le [dÃ©pot de preprocessing](https://github.com/InseeFrLab/satellite-images-preprocess)


## ğŸ“ˆ L'utilisation de MLflow 

