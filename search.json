[
  {
    "objectID": "src/ntts-2025/index.html#context",
    "href": "src/ntts-2025/index.html#context",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Context",
    "text": "Context\n\nInsee maintains a register of localized buildings (RIL)\n\nComprehensive housing data for cities with over 10k inhabitants 🏙️\nUsed to create sampling frames for census surveys 📋\n\nThe RIL quality is good in metropolitan France ✅…\n\n…but France also includes overseas territories (OTs)! 🌎\nThere, data quality is significantly lower ⚠️"
  },
  {
    "objectID": "src/ntts-2025/index.html#census-in-overseas-territories",
    "href": "src/ntts-2025/index.html#census-in-overseas-territories",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Census in Overseas Territories",
    "text": "Census in Overseas Territories\n\nA cartographic survey is conducted in OTs before each census\nCritical context, particularly in Mayotte and French Guiana:\n\nLocal authorities question official statistics\nRapid urban development\nDifficult field conditions\n\nRequires significant work and is highly costly 💰\nCan we use satellite imagery to optimize census processes in OTs? 🛰️\n\n\n\nSatellite data as supporting evidence:\n\nIndependent information source 🔍\nContinuous territorial monitoring 🔄\nTransparent and reproducible methodology 📑"
  },
  {
    "objectID": "src/ntts-2025/index.html#our-use-cases",
    "href": "src/ntts-2025/index.html#our-use-cases",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Our use cases",
    "text": "Our use cases\n\nPre-cartographic survey:\n\nIdentify priority areas for fieldwork 🎯\nDetect building changes since last survey 🏗️\nPerform temporal comparisons using historical and recent imagery 📆\n\nPost-cartographic survey:\n\nAutomated change detection 🤖\nAnalysis of land-use evolution 🌳➡️🏘️\nAssist population estimates in OTs 📊\n\nExtraordinary use case: Rapid response after devastating tropical cyclone “Chido”"
  },
  {
    "objectID": "src/ntts-2025/index.html#semantic-segmentation",
    "href": "src/ntts-2025/index.html#semantic-segmentation",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Semantic segmentation",
    "text": "Semantic segmentation\n\nPleiades © CNES_2022, Distribution AIRBUS DS"
  },
  {
    "objectID": "src/ntts-2025/index.html#training-a-segmentation-model",
    "href": "src/ntts-2025/index.html#training-a-segmentation-model",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Training a segmentation model",
    "text": "Training a segmentation model\n\nModel trained for automatic segmentation from annotated examples\nRequirements:\n\nSatellite image collection 🛰️\nProduction of annotations (building footprints or land cover, if available) 📍\n\nModel learns to reproduce annotations from images aiming to generalize on new images 🎯"
  },
  {
    "objectID": "src/ntts-2025/index.html#from-segmentation-to-change-detection",
    "href": "src/ntts-2025/index.html#from-segmentation-to-change-detection",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "From segmentation to change detection",
    "text": "From segmentation to change detection"
  },
  {
    "objectID": "src/ntts-2025/index.html#model-used",
    "href": "src/ntts-2025/index.html#model-used",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Model used",
    "text": "Model used\n\nModel architecture 🧩:\n\nBackbone: SegFormer (MiT)\nEncoder: Transformer-based (efficient self-attention, no positional encoding) ⚙️\nDecoder: Lightweight MLP head ✨\n\nWhy SegFormer? 🚀:\n\nNo complex decoders → Efficient & scalable ⚡\nCaptures local & global context → High accuracy 🎯\nNo positional embeddings → Improved resolution generalization 📐\n\nFine-tuned on our dataset 🗃️"
  },
  {
    "objectID": "src/ntts-2025/index.html#pléiades-very-high-resolution",
    "href": "src/ntts-2025/index.html#pléiades-very-high-resolution",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Pléiades (Very High Resolution) 🛰️",
    "text": "Pléiades (Very High Resolution) 🛰️\n\n\n4 characteristics to look at:\n\nSpatial resolution 📐\nAcquisition frequency 🔄\nSpectral resolution 🌈\nGeographic coverage 🌍\n\n\n\n\nCharacteristics:\n\n0.5m × 0.5m spatial resolution 🔍\n3 spectral bands (RGB) 🎨\nFree archives, on-demand acquisition (6-8 months per department), Airbus © licensing 📅\nImage size: 1 km² (2000 × 2000 pixels) 🖼️"
  },
  {
    "objectID": "src/ntts-2025/index.html#sentinel-2-high-resolution",
    "href": "src/ntts-2025/index.html#sentinel-2-high-resolution",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Sentinel-2 (High Resolution) 🛰️",
    "text": "Sentinel-2 (High Resolution) 🛰️\n\nCharacteristics:\n\n10m × 10m spatial resolution 🔍\n13 spectral bands 🎨\n5-day revisit time, free access 🔄🆓\nImage size: 6.25 km² (250 × 250 pixels) 🖼️"
  },
  {
    "objectID": "src/ntts-2025/index.html#reference-data-cosia",
    "href": "src/ntts-2025/index.html#reference-data-cosia",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Reference Data (COSIA)",
    "text": "Reference Data (COSIA)\n\nSignificant project by IGN colleagues 👏\nLand cover generated by AI as vector polygons for France and OTs 🗺️\nBased on IGN aerial photography at 20cm (!!) resolution\nUsed as label for training data despite potential temporal misalignment"
  },
  {
    "objectID": "src/ntts-2025/index.html#interactive-dashboard",
    "href": "src/ntts-2025/index.html#interactive-dashboard",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Interactive Dashboard 📊",
    "text": "Interactive Dashboard 📊\n\n🌟 A picture is worth a thousand words! 🌟\n👉 Access the interactive app: Click here 🚀\n\n\n\nDecided to build a tiny webapp … but we are datascientists be indulgent\nWe computed building areas from our predictions this we get binary value for each pixel and aggregated by admin level\n\n⚠️ Disclaimer : This is a an early stage of our application. 0 check or data quality process have been done.\n\nStandard leaflet map with open Street map layer show Pleiades 2023\n\n97611 0332 : nuages in 2022\n97610ﾠ0608 : different methodology of blurring for prison\n97611 0237 : Our use case : detect building changes in precarious areas\n\nAdministrative-level monitoring of building changes:\n\nSelection by administrative units (municipalities, districts)\nQuality control of detected changes\n\nKey features:\n\nSide-by-side temporal comparison\nStatistical indicators by area\nInteractive visual validation"
  },
  {
    "objectID": "src/ntts-2025/index.html#processing-pipeline",
    "href": "src/ntts-2025/index.html#processing-pipeline",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Processing Pipeline 🛠️",
    "text": "Processing Pipeline 🛠️\n\n\n\n\n\n\n\n\n\n\n\nStandardization of data acquisition—currently rudimentary. Need cloud-free, date-specific images with consistent methodology (challenge with Pléiades).\nTraining stage: cloud removal, dataset balancing, labeling, splitting.\nPyTorch with pre-trained model from HuggingFace (requires GPU).\nAPI building: prediction of images, clustering/bounding boxes, and statistics computation (building area).\nDeployment via GeoServer and web application.\nResults utilized by INSEE colleagues for statistical analyses."
  },
  {
    "objectID": "src/ntts-2025/index.html#application-architecture",
    "href": "src/ntts-2025/index.html#application-architecture",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Application Architecture 🧩",
    "text": "Application Architecture 🧩\n\n\nGeoServer dynamically serves satellite images."
  },
  {
    "objectID": "src/ntts-2025/index.html#challenges-perspectives",
    "href": "src/ntts-2025/index.html#challenges-perspectives",
    "title": "Enhancing census surveys using satellite imagery",
    "section": "Challenges & Perspectives",
    "text": "Challenges & Perspectives\n\nHigh maintenance costs due to technical complexity 💸\nNeed for specialized skills 🧑‍💻\nComplex technical environment due to:\n\nLarge data volumes 🗃️\nHigh computational requirements ⚡\nReproducibility requirements ♻️\n\nPromising initial results supporting cartographic surveys ✅🗺️\nPotential improvements identified for each pipeline stage 🔧"
  },
  {
    "objectID": "src/documentation/index.html",
    "href": "src/documentation/index.html",
    "title": "🧑‍🤝‍🧑Équipe CRaTT",
    "section": "",
    "text": "Raya Berova (DMRG) : raya.berova@insee.fr\nThomas Faria (SSPLab) : thomas.faria@insee.fr\nClément Guillo (DIRAG) : clement.guillo@insee.fr",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Présentation du projet"
    ]
  },
  {
    "objectID": "src/documentation/index.html#les-différents-dépôts",
    "href": "src/documentation/index.html#les-différents-dépôts",
    "title": "🧑‍🤝‍🧑Équipe CRaTT",
    "section": "📁 Les différents dépôts",
    "text": "📁 Les différents dépôts\n\n1️⃣ Astrovision : Package utilitaire pour le traitement d’images satellites\nPour manipuler des données géospatiales, la bibliothèque incontournable est GDAL. Afin de faciliter son usage en Python, des wrappers comme Rasterio sont couramment utilisés. Rasterio offre une interface efficace pour travailler avec des données raster.\nDans notre projet, nous avons développé un package complémentaire, Astrovision, qui centralise un ensemble de fonctions utilitaires : découpage d’images, gestion des métadonnées, visualisation, etc. Ce package n’est pas strictement indispensable, cela a été aussi pour nous d’apprendre à déployer un package python. Le projet pourrait fonctionner en s’appuyant exclusivement sur Rasterio, avec quelques adaptations.\n\n\n2️⃣ Préparation des images satellites\nLe dépôt satellite-images-preprocess regroupe les fonctions nécessaires à la préparation des images avant l’entraînement des modèles. Ce dépôt n’est utilisé qu’en amont d’un entraînement, et n’est donc pas utile lorsque l’on souhaite simplement réaliser de l’inférence sur de nouvelles images.\nLe pipeline de preprocessing comprend les étapes suivantes :\n\nGénération automatique des labels à partir d’un jeu d’annotations.\nDécoupage des images sources en tuiles plus petites (pour éviter les problèmes de mémoire lors de l’entraînement).\nSuppression des images contenant des nuages.\nFiltrage des images selon une région d’intérêt définie.\nCalcul des moyennes et écarts types des bandes spectrales pour la normalisation.\nRéalisation du split train/test et sauvegarde des données sur un bucket S3.\n\n\n\n\n\n\n\nNote\n\n\n\nLe choix de séparer ce dépôt de celui de l’entraînement est discutable, mais repose sur plusieurs objectifs :\n\nIsoler les différentes étapes du pipeline.\nÉviter de ré-exécuter inutilement le preprocessing à chaque entraînement.\nFaciliter la modularité du projet. Ces objectifs ne sont pas forcément en contradiction avec le fait de tout centraliser dans un seul package.\n\n\n\n\n\n3️⃣ Entraînement des modèles\nL’entraînement est géré par le dépôt satellite-images-train. Il est nécessaire d’avoir à disposition des images déjà prétraitées et stockées sur le S3, ce qui peut être fait via le dépôt de preprocessing.\nL’objectif de ce dépôt est d’offrir un environnement modulaire permettant d’expérimenter différentes stratégies d’entraînement et d’optimiser les hyperparamètres propre à l’entraînement (et rien d’autres !). Tous les résultats sont loggués via MLFlow.\nDeux familles de modèles de segmentation sont actuellement intégrées :\n\nDeepLabv3 (et sa variante binaire).\nSegformer, de b0 à b5.\n\nCôté fonctions de perte, plusieurs variantes de l’entropie croisée sont disponibles (classique, pondérée, binaire, etc.).\n\n\n4️⃣ Inférence à partir de nouvelles images\nLe dépôt satellite-images-inference est dédié à l’inférence. C’est peut être le dépôt le moins “isolé” dans le sens où il contient à la fois les codes de l’API qui est utilisée pour réaliser l’inférence mais également divers scripts nécessaires que cela soit pour l’inférence, le post-processing ou bien la reception de nouvelles images à inférer.\nL’API, développée avec FastAPI, est déployée sur SSPCloud. Elle propose trois endpoints principaux :\n\nGET /predict_image — Prédiction d’une image individuelle stockée sur S3.\nGET /predict_cluster — Prédiction sur un îlot identifié par son code (peut inclure plusieurs images).\nGET /predict_bbox — Prédiction sur une bounding box définie par des coordonnées GPS (peut inclure plusieurs images).\n\nUn système de cache est en place pour éviter les redondances de calcul sur une même image.\n\n\n\n\n\n\n⚠️ Limites actuelles de l’API :\n\n\n\n\nLes prédictions en batch ne sont pas possibles directement (elles doivent être séquentielles) puisque seuls des endpoints GET sont disponibles.\nCertaines opérations pourraient être asynchrones pour améliorer les performances.\nL’API reproduit le preprocessing, idéalement, il faudrait wrapper tout dans un modèle MLFlow et donc créer une custom class lors de l’entrainement.\n\n\n\n\n\n5️⃣ Application CRaTT\nLe code de l’application CRaTT permettant de visualiser les résultats sur des territoires entier est disponible dans le dépôt satellite-images-webapp. L’application est construite avec Observable Framework qui permet de déployer sur un site statique tout en gardant un certain niveau d’interactivité dans les visualisations que l’on peut montrer. La manipulation des données peut se faire dans le langage de notre choix (Python, R, SQL, etc.) et les visualisation se font en JavaScript.\nLe déploiement est réalisé via Github Pages et est accessible à l’adresse suivante : https://inseefrlab.github.io/satellite-images-webapp/.\n\n\n6️⃣ Déploiement des applications\nPour gérer les différents déploiements de l’ensemble du projet, nous avons créer un dépôt GitOps. Il s’agit du dépôt satellite-images-cd. Il contient les manifests Kubernetes des services déployés ainsi que les templates d’ArgoCD afin d’avoir un déploiement continu.\nEn avril 2025, 2 services sont déployés :\n\nl’API d’inférence\nle Geoserver pour la mise à disposition des tuiles d’images\n\n\n\n7️⃣ Documentation du projet\nLa documentation que vous lisez actuellement est réaliser avec Quarto et toute contribution est la bienvenue dans le dépôt satellite-images-docs.",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Présentation du projet"
    ]
  },
  {
    "objectID": "src/documentation/index.html#le-projet-sur-le-datalab-sspcloud",
    "href": "src/documentation/index.html#le-projet-sur-le-datalab-sspcloud",
    "title": "🧑‍🤝‍🧑Équipe CRaTT",
    "section": "Le projet sur le Datalab – SSPCloud",
    "text": "Le projet sur le Datalab – SSPCloud\n\nLe namespace\nAfin de pouvoir contribuer au projet il est nécessaire d’avoir accès au namespace projet-slums-detection. Pour cela, vous pouvez contacter la Diit.\n\n\nLes données\nLe S3 associé au projet est structuré en plusieurs dossiers.\n\n📁 data-raw\nCe dossier contient les images satellites telles qu’on les reçoit sans modification. Seules les données de la Guyane et de Saint-Martin sont un peu différentes avec des sous dossiers brut car elles ont nécessité des ajustements préalables. En effet, pour tous les autres départements les données proviennent de l’IGN qui nous transmets les mosaïques d’images 2000x2000.\nLa structure du dossier est :\ndata-raw/&lt;SOURCE&gt;/&lt;DEPARTEMENT&gt;/&lt;ANNEE&gt;/*.tif\n\n\n📁 data-label\nCe dossier contient les données géographiques contenant les labels que nous utilisons lors de notre entraînement et que nous considérons donc comme vraie valeur. En fonction de la source de l’annotation le format des fichiers peut différer. Pour le moment, 2 sources de données sont utilisées il s’agit de la BDTOPO et de COSIA et les données sont stockées respectivement au format Shapefile et au format Geopackage.\nLa structure du dossier est :\ndata-label/\n├── BDTOPO/\n│   ├── bdtopo-id2label.json\n│   └── &lt;DEPARTEMENT&gt;/\n│       └── &lt;ANNEE&gt;/\n├── COSIA/\n│   ├── cosia-id2label.json\n│   └── &lt;DEPARTEMENT&gt;/\n│       └── &lt;ANNEE&gt;/\n\n\n📁 data-preprocessed\nLe dossier data-preprocessed/ contient l’ensemble des données préparées pour l’entraînement d’un modèle. Il est organisé en deux sous-dossiers principaux, le dossier labels/ qui contient les fichiers d’étiquettes (.npy) associés à chaque tuile d’image ainsi que le dossier patchs/ contient les images (.jp2) associées portant le même nom.\nLa structure du dossier est donc :\ndata-preprocessed/\n├── labels/                        # Étiquettes\n│   └── &lt;LABELER&gt;/                 # Annotateur (ex: COSIA, BDTOPO...)\n│       └── &lt;TASK&gt;/                # Tâche spécifique (ex: segmentation, classification...)\n│           └── &lt;SOURCE&gt;/          # Source de données (ex: PLEIADES, SENTINEL...)\n│               └── &lt;DEPARTEMENT&gt;/ # Département (ex: MAYOTTE, REUNION...)\n│                   └── &lt;ANNEE&gt;/   # Année de la donnée (ex: 2023)\n│                       └── &lt;TILE-SIZE&gt;/  # Taille des tuiles (ex: 125, 250...)\n│                           ├── train/    # Jeu d'entraînement\n│                           │   └── *.npy # Fichiers numpy\n│                           └── test/     # Jeu de test\n│                               └── *.npy # Fichiers numpy\n├── patchs/                        # Images\n│   └── &lt;LABELER&gt;/                 # Annotateur (ex: COSIA, BDTOPO...)\n│       └── &lt;TASK&gt;/                # Tâche spécifique (ex: segmentation, classification...)\n│           └── &lt;SOURCE&gt;/          # Source de données (ex: PLEIADES, SENTINEL...)\n│               └── &lt;DEPARTEMENT&gt;/ # Département (ex: MAYOTTE, REUNION...)\n│                   └── &lt;ANNEE&gt;/   # Année de la donnée (ex: 2023)\n│                       └── &lt;TILE-SIZE&gt;/  # Taille des tuiles (ex: 125, 250...)\n│                           ├── train/    # Jeu d'entraînement\n│                           │   └── *.jp2 # Fichiers images jp2\n│                           └── test/     # Jeu de test\n│                               └── *.jp2 # Fichiers images jp2\n\n\n\n📁 data-prediction\nLe dossier data-prediction/regroupe les résultats de prédictions générées par différents modèles. Les prédictions sont disponibles au format Parquet mais également au format GeoPackage pour pouvoir les utiliser dans le Geoserver.\nLa structure du dossier est :\ndata-prediction/\n└── &lt;SOURCE&gt;/                  # Source de données (ex: PLEIADES, SENTINEL...)\n    └── &lt;DEPARTEMENT&gt;/          # Département (ex: MAYOTTE, REUNION...)\n        └── &lt;ANNEE&gt;/            # Année de la donnée (ex: 2023)\n            └── &lt;MODEL-NAME&gt;/   # Nom du modèle utilisé pour la prédiction\n                └── &lt;MODEL-VERSION&gt;/ # Version du modèle (ex: 1, 2...)\n                    ├── *.parquet    # Fichiers de prédiction au format parquet\n                    └── *.gpkg       # Fichiers de prédiction au format GeoPackage\n\n\n📁 cache-predictions\nLe dossier cache-predictions/ contient les logits intermédiaires produits par les modèles lors du processus de prédiction afin de ne pas refaire une prédiction qui aurait déjà été réalisée. L’organisation du dossier reprend la même hiérarchie que data-prediction :\ncache-predictions/\n└── &lt;SOURCE&gt;/                  # Source de données (ex: PLEIADES, SENTINEL...)\n    └── &lt;DEPARTEMENT&gt;/          # Département (ex: MAYOTTE, REUNION...)\n        └── &lt;ANNEE&gt;/            # Année de la donnée (ex: 2023)\n            └── &lt;MODEL-NAME&gt;/   # Nom du modèle utilisé pour la prédiction\n                └── &lt;MODEL-VERSION&gt;/ # Version du modèle (ex: 1, 2...)\n                    └── *.npy       # Logits prédits\n\n\n📁 data-roi\nLe dossier data-roi contient les contours géographique de chaque département afin de pouvoir filtrer les images efficacement que ce soit lors de l’étape de preprocessing que lors de l’étape de l’inférence. Les contours sont à la fois stockés en parquet et en geojson (un seul des deux formats pourrait suffire).\nCes données ont été construites à la main à partir de données officielles. Les contours des territoires n’étant pas sensés changer, il n’y a pas à mettre à jour ces données.\nLa structure du dossier est :\ndata-roi/\n├── &lt;DEPARTEMENT&gt;.parquet\n└── &lt;DEPARTEMENT&gt;.geojson\n\n\n📁 cluster-geom-raw\nLe dossier cluster-geom-raw contient tout l’historique des géométries d’îlots non preprocessé.\nLa géométrie des îlots est arrêtée chaque année au 31 octobre ; c’est cette version qui s’applique pendant le recensement de la population (RP).\nPar exemple, pour l’enquête annuelle de recensement 2026, il faudra utiliser la géométrie des îlots arrêtée au 31 octobre 2025.\nDans tous les cas, il est indispensable de s’assurer que le SERN Géographie et le ST Mayotte disposent bien des mêmes référentiels d’îlots. Des ajustements exceptionnels pourraient être nécessaires compte tenu de l’urgence post-Chido.\nUne fois le fichier avec les dernières géométries traité, les nouveaux fichiers parquet sont disponibles dans data-clusters.\n\n\n📁 data-clusters\nLe dossier data-clusters contient les contours géographique de chaque îlot pour les différents départements. Ces informations sont nécessaires lors de l’inférence pour un îlot donné ainsi que pour le déploiement de la webapp qui permet de réaliser des statistiques par îlot. Le dossier est simplement un fichier parquet partitionné :\ndata-clusters/\n├── dep=&lt;DEPARTEMENT&gt;/\n      └── part-0.parquet\n\n\n\nLes services\nLe projet utilise plusieurs service au sein du datalab.\n\nMLFlow\n\nMLflow est utilisé lors de la phase d’entraînement pour tracker et optimiser nos modèles. Il permet de logguer les hyperparamètres, les métriques et les artefacts générés au cours des expérimentations. MLflow joue également le rôle de Model Registry, dans lequel à chaque modèle est associé un tag tel que staging, production ou archived. Cela facilite le versionnement et la bonne gestion du cycle de vie des modèles dans le temps\n\nArgoCD\n\nArgoCD est déployé pour superviser et gérer automatiquement les applications présentes dans notre namespace. Il permet de surveiller en permanence l’état de déploiement des applications et détecte automatiquement toute modification des manifests dans le dépôt GitOps dédié (https://github.com/inseeFrLab/satellite-images-cd). Lorsqu’une modification est détectée, ArgoCD applique automatiquement les changements sur le cluster, garantissant une parfaite synchronisation entre le code source et l’état effectif des déploiements.\n\nArgo Workflows\n\nArgo Workflows est utilisé pour orchestrer l’exécution parallèle de scripts, ce qui optimise considérablement les temps de calcul. Les workflows sont décrits dans des fichiers YAML stockés dans les répertoires argo-workflows/ présents dans les différents dépôts. Argo Workflows est sollicité à différents stades du projet, notamment pour exécuter les étapes de preprocessing des données, l’entraînement de modèles en parallèle, ainsi que l’inférence à grande échelle.\n\nGeoserver\n\nGeoServer permet la publication et la mise à disposition de données géographiques sous forme de flux normalisés (WMS, WFS, WCS). Contrairement aux autres services mentionnés, GeoServer n’est pas directement provisionné par le Datalab, ni déployé via Helm Chart.\nÀ ce jour, GeoServer ne peut pas accéder directement aux fichiers stockés sur un stockage objet type S3. En conséquence, toutes les images ou données que nous souhaitons exposer doivent être dupliquées dans un PVC associé au pod GeoServer…",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Présentation du projet"
    ]
  },
  {
    "objectID": "src/documentation/sections/satellite_image.html",
    "href": "src/documentation/sections/satellite_image.html",
    "title": "Qu’est ce que c’est une image ?",
    "section": "",
    "text": "C’est une matrice en 3 dimensions. Une image classique (RGB) contient 3 bandes, la bande Rouge, la Verte et la Bleue. Chaque bande est égale à une matrice n*m (n et m est le nombre de pixels à l’horizontal et à la verticale). La matrice de chaque bande définie l’intensité de la bande par pixel. Donc une image RGB est une matrice 3*n*m.\n\n\n\nIl existe plusieurs caractéristiques propres aux images satellites :\n\nDate d’acquisition\n\nCRS (Coordinate Reference System)\n\nBounding-box : les 4 points qui géolocalisent l’image (dans l’ordre left bottom right top)\n\nRésolution : un pixel est égal à x cm² (Pléiades = 50cm², Sentinel-2 = 10m²)\n\nNombre de bandes (Pléiades : 3 voire 4, Sentinel-2 : 13)\n\nLes images satellites que nous utilisons sont en format TIF ou JP2.\n\n\nPour prendre en main facilement nos images satellites et accéder à leurs caractéristiques, nous avons créé le package Astrovision. Il permet d’ouvrir une image TIF/JP2, découper l’image, labelliser l’image avec un masque fourni et afficher.",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Une image satellite"
    ]
  },
  {
    "objectID": "src/documentation/sections/satellite_image.html#une-image-satellite",
    "href": "src/documentation/sections/satellite_image.html#une-image-satellite",
    "title": "Qu’est ce que c’est une image ?",
    "section": "",
    "text": "Il existe plusieurs caractéristiques propres aux images satellites :\n\nDate d’acquisition\n\nCRS (Coordinate Reference System)\n\nBounding-box : les 4 points qui géolocalisent l’image (dans l’ordre left bottom right top)\n\nRésolution : un pixel est égal à x cm² (Pléiades = 50cm², Sentinel-2 = 10m²)\n\nNombre de bandes (Pléiades : 3 voire 4, Sentinel-2 : 13)\n\nLes images satellites que nous utilisons sont en format TIF ou JP2.\n\n\nPour prendre en main facilement nos images satellites et accéder à leurs caractéristiques, nous avons créé le package Astrovision. Il permet d’ouvrir une image TIF/JP2, découper l’image, labelliser l’image avec un masque fourni et afficher.",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Une image satellite"
    ]
  },
  {
    "objectID": "src/documentation/sections/acquisition.html",
    "href": "src/documentation/sections/acquisition.html",
    "title": "Acquisition",
    "section": "",
    "text": "Les images Pléiades présentent l’avantage d’offrir une très haute résolution (50 cm). Toutefois, elles sont la propriété d’Airbus, ce qui limite leur accessibilité : l’acquisition passe généralement par un achat de licence. En tant qu’institution française, nous bénéficions d’un accès gratuit à ces données via Dinamis. Il suffit de créer un compte sur Dinamis et de réaliser une demande d’accès. Nous avons un contact à l’IGN pour simplifier la procédure et il nous transmet les images directement. Toutefois, même avec ce canal, il reste nécessaire de créer un compte Dinamis et de signer un contrat de licence d’utilisation.\nLorsque les images sont disponibles, notre interlocuteur à l’IGN nous en informe par mail, en transmettant les accès à un serveur FTP. Les données peuvent alors être extraites puis transférées sur le S3 du namespace projet-slums-detection au sein du Datalab, selon la structure décrite dans @data-raw.\n\n\n\n\n\n\nComment récupérer les images Pléiades de l’IGN ?\n\n\n\n\nOuvrir un service VSCode sur le Datalab. ⚠️ Pour les volumes importants, pensez à augmenter la persistance (ex : 500Gi) lors du lancement du service.\nCloner le dépot d’inférence etaccéder au script bash/download_pleiades_ign.sh.\nRenseigner les informations spécifiques au serveur FTP ainsi que les arguments nécessaires (département, année).\nExécuter le script pour télécharger les données localement dans le service. Vous pouvez ensuite explorer les fichiers comme d’habitude (cd, ls, etc.).\nUne fois en local, vérifiez que les images soient bien au format .tif, si ce n’est pas le cas, exécuter le script src/write_jp2_to_tiff.py pour les convertir et les stocker sur le S3\n\n\n\n\n\n\nPour un accès libre et beaucoup plus rapide, l’utilisation des images Sentinel-2 constitue une alternative intéressante. Ces images ont une résolution de 10 mètres. Les images Sentinel-2 peuvent être récupérées via différentes plateformes comme Google Earth Engine, Sentinel Hub ou encore Copernicus Data Space Ecosystem. Un exemple d’utilisation et de téléchargement de ces données est disponible dans le dépôt Hackathon NTTS 2025, en consultant le script preprocess/main_nuts.py.\n\n\n\n\n\n\nLa BD TOPO est une description vectorielle 3D (structurée en objets) des éléments du territoire et de ses infrastructures, de précision métrique, exploitable à des échelles allant du 1 : 2 000 au 1 : 50 000.\nLes objets de la BD TOPO® sont regroupés par thèmes :\n\nAdministratif (limites et unités administratives) ;\nBâti (constructions) ;\nHydrographie (éléments ayant trait à l’eau) ;\nLieux nommés (lieu ou lieu-dit possédant un toponyme et décrivant un espace naturel ou un lieu habité) ;\nOccupation du sol (végétation, estran, haie) ;\nServices et activités (services publics, stockage et transport des sources d’énergie, lieux et sites industriels) ;\nTransport (infrastructures du réseau routier, ferré et aérien, itinéraires) ;\nZones réglementées (la plupart des zonages faisant l’objet de réglementations spécifiques).\n\nDans notre cas, seule la couche Bâti a été utilisée.\n\n\n\n\n\n\nComment récupérer les données de la BDTOPO\n\n\n\nLes données de la BDTOPO sont accessibles au format archivé 7z soit en shapefile soit en geopackage à l’adresse suivante : https://geoservices.ign.fr/bdtopo#telechargementgpkgreg. Elle est stockée par département.\n\n\n\n\n\nLes cartes CoSIA décrivent la couverture du sol, soit la nature du sol, selon 16 classes (bâtiment, surface d’eau, conifère, culture, broussaille…). Cette description du sol est produite pour tout le territoire français (métropole et DROM) et avec une haute résolution de 20 cm par pixel. Ces annotations ont été obtenues par l’IGN à l’aide d’un modèle de ML. Il faut donc bien garder en tête qu’on utilise des prédictions d’un modèle comme ground truth.\n\n\n\n\n\n\nComment récupérer les données de COSIA\n\n\n\n\nAccéder au site COSIA\nRemplir le formulaire d’accès et sélectionner le territoire d’intérêt. Télécharger le fichier .zip\nL’importer dans un service du Datalab, le décompresser (commande unzip sous Linux) et organiser les fichiers selon la structure attendue sur S3.\n\n\n\n\n\n\nLa géographie des ilots est arrêtée chaque année au 31 octobre.\nC’est cette géographie qui s’applique pendant le Recensement de la Population (RP).\n\n📌 Exemple : pour l’enquête de recensement 2026, on utilise la géométrie des ilots arrêtée au 31 octobre 2025.\n\nDans tous les cas, il faut s’assurer que le SERN Géographie et le ST Mayotte utilisent bien la même version des ilots (des changements exceptionnels peuvent être demandés en cas d’urgence).\n\n\n\n\n\n\nComment récupérer les géométries d’ilots ?\n\n\n\n\nEnvoyer un mail au SERN géographie\n\nRécupérer le dossier zip fourni et le placer dans le dossier cluster-geom-raw sur le s3\n\nLancer ce code pour preprocesser le dossier afin de créer un fichier parquet par département qui se placeront dans le dossier data-clusters",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Acquisition"
    ]
  },
  {
    "objectID": "src/documentation/sections/acquisition.html#images-satellite",
    "href": "src/documentation/sections/acquisition.html#images-satellite",
    "title": "Acquisition",
    "section": "",
    "text": "Les images Pléiades présentent l’avantage d’offrir une très haute résolution (50 cm). Toutefois, elles sont la propriété d’Airbus, ce qui limite leur accessibilité : l’acquisition passe généralement par un achat de licence. En tant qu’institution française, nous bénéficions d’un accès gratuit à ces données via Dinamis. Il suffit de créer un compte sur Dinamis et de réaliser une demande d’accès. Nous avons un contact à l’IGN pour simplifier la procédure et il nous transmet les images directement. Toutefois, même avec ce canal, il reste nécessaire de créer un compte Dinamis et de signer un contrat de licence d’utilisation.\nLorsque les images sont disponibles, notre interlocuteur à l’IGN nous en informe par mail, en transmettant les accès à un serveur FTP. Les données peuvent alors être extraites puis transférées sur le S3 du namespace projet-slums-detection au sein du Datalab, selon la structure décrite dans @data-raw.\n\n\n\n\n\n\nComment récupérer les images Pléiades de l’IGN ?\n\n\n\n\nOuvrir un service VSCode sur le Datalab. ⚠️ Pour les volumes importants, pensez à augmenter la persistance (ex : 500Gi) lors du lancement du service.\nCloner le dépot d’inférence etaccéder au script bash/download_pleiades_ign.sh.\nRenseigner les informations spécifiques au serveur FTP ainsi que les arguments nécessaires (département, année).\nExécuter le script pour télécharger les données localement dans le service. Vous pouvez ensuite explorer les fichiers comme d’habitude (cd, ls, etc.).\nUne fois en local, vérifiez que les images soient bien au format .tif, si ce n’est pas le cas, exécuter le script src/write_jp2_to_tiff.py pour les convertir et les stocker sur le S3\n\n\n\n\n\n\nPour un accès libre et beaucoup plus rapide, l’utilisation des images Sentinel-2 constitue une alternative intéressante. Ces images ont une résolution de 10 mètres. Les images Sentinel-2 peuvent être récupérées via différentes plateformes comme Google Earth Engine, Sentinel Hub ou encore Copernicus Data Space Ecosystem. Un exemple d’utilisation et de téléchargement de ces données est disponible dans le dépôt Hackathon NTTS 2025, en consultant le script preprocess/main_nuts.py.",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Acquisition"
    ]
  },
  {
    "objectID": "src/documentation/sections/acquisition.html#labels-pour-lentraînement-du-modèle",
    "href": "src/documentation/sections/acquisition.html#labels-pour-lentraînement-du-modèle",
    "title": "Acquisition",
    "section": "",
    "text": "La BD TOPO est une description vectorielle 3D (structurée en objets) des éléments du territoire et de ses infrastructures, de précision métrique, exploitable à des échelles allant du 1 : 2 000 au 1 : 50 000.\nLes objets de la BD TOPO® sont regroupés par thèmes :\n\nAdministratif (limites et unités administratives) ;\nBâti (constructions) ;\nHydrographie (éléments ayant trait à l’eau) ;\nLieux nommés (lieu ou lieu-dit possédant un toponyme et décrivant un espace naturel ou un lieu habité) ;\nOccupation du sol (végétation, estran, haie) ;\nServices et activités (services publics, stockage et transport des sources d’énergie, lieux et sites industriels) ;\nTransport (infrastructures du réseau routier, ferré et aérien, itinéraires) ;\nZones réglementées (la plupart des zonages faisant l’objet de réglementations spécifiques).\n\nDans notre cas, seule la couche Bâti a été utilisée.\n\n\n\n\n\n\nComment récupérer les données de la BDTOPO\n\n\n\nLes données de la BDTOPO sont accessibles au format archivé 7z soit en shapefile soit en geopackage à l’adresse suivante : https://geoservices.ign.fr/bdtopo#telechargementgpkgreg. Elle est stockée par département.\n\n\n\n\n\nLes cartes CoSIA décrivent la couverture du sol, soit la nature du sol, selon 16 classes (bâtiment, surface d’eau, conifère, culture, broussaille…). Cette description du sol est produite pour tout le territoire français (métropole et DROM) et avec une haute résolution de 20 cm par pixel. Ces annotations ont été obtenues par l’IGN à l’aide d’un modèle de ML. Il faut donc bien garder en tête qu’on utilise des prédictions d’un modèle comme ground truth.\n\n\n\n\n\n\nComment récupérer les données de COSIA\n\n\n\n\nAccéder au site COSIA\nRemplir le formulaire d’accès et sélectionner le territoire d’intérêt. Télécharger le fichier .zip\nL’importer dans un service du Datalab, le décompresser (commande unzip sous Linux) et organiser les fichiers selon la structure attendue sur S3.\n\n\n\n\n\n\nLa géographie des ilots est arrêtée chaque année au 31 octobre.\nC’est cette géographie qui s’applique pendant le Recensement de la Population (RP).\n\n📌 Exemple : pour l’enquête de recensement 2026, on utilise la géométrie des ilots arrêtée au 31 octobre 2025.\n\nDans tous les cas, il faut s’assurer que le SERN Géographie et le ST Mayotte utilisent bien la même version des ilots (des changements exceptionnels peuvent être demandés en cas d’urgence).\n\n\n\n\n\n\nComment récupérer les géométries d’ilots ?\n\n\n\n\nEnvoyer un mail au SERN géographie\n\nRécupérer le dossier zip fourni et le placer dans le dossier cluster-geom-raw sur le s3\n\nLancer ce code pour preprocesser le dossier afin de créer un fichier parquet par département qui se placeront dans le dossier data-clusters",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Acquisition"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projet Données Satellites",
    "section": "",
    "text": "Description : Ici est rassemblée toute la documentation technique sur le travail effectué au cours de l'expérimentation sur les données satellite\n\n            \n\n            \n            \n              \n                Raya Berova, Gaëtan Carrere, Thomas Faria, Clément Guillo et Tom Seimandi\n                May 26, 2025\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        doc\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : Application web à destination des agents facilitant l'utilisation des résultats fournis par le modèle de segmentation.\n\n            \n\n            \n            \n              \n                \n                May 26, 2025\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        CraTT\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : Document retraçant les avancées et résultats obtenus sur les travaux exploratoires utilisant des images satellitaires\n\n            \n\n            \n            \n              \n                Raya Berova, Gaëtan Carrere, Thomas Faria, Clément Guillo et Tom Seimandi\n                May 16, 2024\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        pdf\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : Ce séminaire marque la fin des travaux d’expérimentation. À cette occasion, nous présenterons l’intégralité de la chaîne de traitement, de la récupération des images jusqu’à l’application d’aide à la décision, en mettant l’accent sur les difficultés rencontrées. La poursuite de ces travaux dépendra des besoins réels de l’Insee et nécessitera des compétences variées et une technicité élevée pour maintenir et/ou améliorer la chaîne de traitement.\n\n            \n\n            \n            \n              \n                Raya Berova, Gaëtan Carrere, Thomas Faria, Clément Guillo et Tom Seimandi\n                May 28, 2024\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        Slides\n                      \n                    \n                  \n                \n              \n              \n              \n                \n                  \n                    \n                      \n                        Vidéo\n                      \n                    \n                  \n                \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : Slideshow presentation of the project Detecting changes in buildings in French overseas departments for Work Package 7,\nArtificial Intelligence and Machine Learning for Official Statistics, organized by Eurostat.\n\n            \n\n            \n            \n              \n                Raya Berova, Thomas Faria et Clément Guillo\n                Nov 13, 2024\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        Slides\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : Slide deck for the NTTS 2025 conference.\n\n            \n\n            \n            \n              \n                Raya Berova, Thomas Faria et Clément Guillo\n                Mar 12, 2025\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        Slides\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : TODO\n\n            \n\n            \n            \n              \n                Raya Berova, Thomas Faria et Clément Guillo\n                Nov 19, 2024\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        Slides\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#documents-relatifs-au-projet-sur-les-données-satellites-à-linsee",
    "href": "index.html#documents-relatifs-au-projet-sur-les-données-satellites-à-linsee",
    "title": "Projet Données Satellites",
    "section": "",
    "text": "Description : Ici est rassemblée toute la documentation technique sur le travail effectué au cours de l'expérimentation sur les données satellite\n\n            \n\n            \n            \n              \n                Raya Berova, Gaëtan Carrere, Thomas Faria, Clément Guillo et Tom Seimandi\n                May 26, 2025\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        doc\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : Application web à destination des agents facilitant l'utilisation des résultats fournis par le modèle de segmentation.\n\n            \n\n            \n            \n              \n                \n                May 26, 2025\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        CraTT\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : Document retraçant les avancées et résultats obtenus sur les travaux exploratoires utilisant des images satellitaires\n\n            \n\n            \n            \n              \n                Raya Berova, Gaëtan Carrere, Thomas Faria, Clément Guillo et Tom Seimandi\n                May 16, 2024\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        pdf\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : Ce séminaire marque la fin des travaux d’expérimentation. À cette occasion, nous présenterons l’intégralité de la chaîne de traitement, de la récupération des images jusqu’à l’application d’aide à la décision, en mettant l’accent sur les difficultés rencontrées. La poursuite de ces travaux dépendra des besoins réels de l’Insee et nécessitera des compétences variées et une technicité élevée pour maintenir et/ou améliorer la chaîne de traitement.\n\n            \n\n            \n            \n              \n                Raya Berova, Gaëtan Carrere, Thomas Faria, Clément Guillo et Tom Seimandi\n                May 28, 2024\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        Slides\n                      \n                    \n                  \n                \n              \n              \n              \n                \n                  \n                    \n                      \n                        Vidéo\n                      \n                    \n                  \n                \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : Slideshow presentation of the project Detecting changes in buildings in French overseas departments for Work Package 7,\nArtificial Intelligence and Machine Learning for Official Statistics, organized by Eurostat.\n\n            \n\n            \n            \n              \n                Raya Berova, Thomas Faria et Clément Guillo\n                Nov 13, 2024\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        Slides\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : Slide deck for the NTTS 2025 conference.\n\n            \n\n            \n            \n              \n                Raya Berova, Thomas Faria et Clément Guillo\n                Mar 12, 2025\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        Slides\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n  \n     \n      \n        \n          \n            \n          \n         \n        \n          \n            \n            \n\n            \n              Description : TODO\n\n            \n\n            \n            \n              \n                Raya Berova, Thomas Faria et Clément Guillo\n                Nov 19, 2024\n              \n            \n            \n            \n              \n              \n                \n                  \n                    \n                      \n                        Slides\n                      \n                    \n                  \n                \n              \n              \n              \n            \n          \n        \n\n        \n\n      \n     \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "src/documentation/sections/timeline.html",
    "href": "src/documentation/sections/timeline.html",
    "title": "Projet Données Satellites",
    "section": "",
    "text": "MARS 2022\nClément Guillo prend un stagiaire de Master et se lance sur le sujet des images satellites.\n\n\nNOV 2022\nClément Guillo initie le projet Images Satellites avec Tom Seimandi et Thomas Faria au SSPLab.\nIls trouvent comme cas d’usage l’aide à l’enquête cartographique dans les DROM pour mieux\ndiriger les agents recenseurs lors des collectes ⟶ Début du projet !\n\n\nMARS 2023\nStages de fin d'études : \n  Judith Nabec sur les images Sentinel2 (DG),\n  Raya Berova sur les images Pléïades (DIRAG puis DG)\n\n\nSEPT 2023\nRaya Berova intègre l’équipe, avec 0.2 ETP sur le projet.\nTravail de mise au propre du code du projet.\nEntraînement d’un nouveau modèle très performant, qui est devenu le modèle actuellement\nutilisé : le SegFormer.\nLe modèle prédit uniquement le bâti sur images Pléïades, entraîné sur la BDTOPO.\n\n\nDEC 2023\nMise en place du GeoServer puis de l’application web CRaTT pour afficher dynamiquement les\nimages et les prédictions. Permet un contrôle visuel facile pour l’équipe et de diffuser\nles travaux à l’Insee.\nCréation du package Astrovision pour faciliter la lecture et la manipulation des\nimages satellites.\n\n\nMARS 2024\nStagiaire de Master sur le traitement des prédictions du modèle\n⟶ mise en forme des prédictions, nettoyage et statistiques.\n\n\nMAI 2024\nSéminaire DIRAG : rencontre des équipes.\n  Guadeloupe : présentation du projet à la DIRAG.\n  Guyane : discussions des cas d’usages et réalisation de l’enquête cartographique sur\n  le terrain. Visite de quartiers et de bidonvilles.\n\n\nSEPT 2024\nDépart de Tom Seimandi.\n\n\nDEC 2024\nMeeting WP7 : rencontre avec l’IGN et présentation de COSIA\n⟶ entraînement d’un modèle multiclasse grâce aux annotations de COSIA. Modèle plus\nperformant que l’ancien, il est actuellement utilisé.\nParticipation active lors des GT DOM Résil : est-ce que le projet peut aider à estimer\nle nombre de logements à Mayotte ?\n\n\nFEV 2025\nPrise de contact avec Pascal Rivière et Loup Wolff pour savoir si CRaTT peut aider au recensement\nexhaustif de Mayotte 2026 et estimer les zones les plus touchées par le cyclone Chido.\n\n\nMARS 2025\nHackathon Eurostat à Bruxelles sur les données satellites : 6ième place sur 27 équipes\n(Clément, Raya et Damien Babet du SSM Agri)\n⟶ reproduction du projet de A à Z en 3 jours en utilisant des images\nSentinel2 et les annotations CLCPlus sur les pays de l’UE.\nPrésentation du projet à NTTS (Thomas).\n\n\nÉTÉ 2025\nDépart de Thomas Faria et Clément Guillo.\nTravail de documentation.\nPassation pour préparer l’arrivée de Meilame et Cédric SSPLab.\n\n\nSUITE\nJMS avec la DMTR : utilisation des images satellites pour améliorer le repérage\ndes logements à Mayotte.\nDéplacement à Varsovie pour le WP7.\nLa suite est à déterminer."
  },
  {
    "objectID": "src/documentation/sections/entrainement.html",
    "href": "src/documentation/sections/entrainement.html",
    "title": "Entraînement d’un modèle",
    "section": "",
    "text": "Lien vers le dépôt d’entraiement : https://github.com/InseeFrLab/satellite-images-train.\n\n\n\n\ngit clone https://github.com/InseeFrLab/satellite-images-train.git\ncd satellite-images-train\nuv sync\nuv run pre-commit install\n\n\n\nDéfinissez les paramètres d’entraînement puis exécutez :\nbash bash/mlflow-run.sh\nL’ensemble de l’exécution sera automatiquement enregistré dans MLflow.\n\n\n\n\nMettez à jour les paramètres dans argo-workflows/train-workflow.yaml argo-workflows/train-workflow.yaml.\nSoumettez le workflow via l’interface CLI ou l’interface graphique Argo en copier/collant le template:\n\nargo submit argo-workflows/train-workflow.yaml\n\n\n\n\nLe pipeline d’entraînement est construit avec PyTorch et conçu pour être flexible :\n\nArchitectures : deeplabv3, segformer-b[0–5], single_class_deeplabv3\nFonctions de perte: Cross-Entropy (avec différentes variantes), BCE, BCE avec logits\nSchedulers: reduce_on_plateau, one_cycle, etc.\nSources des labels: BDTOPO, COSIA ou autres.\n\nDe nouveaux modèles peuvent être implémenter en rajoutant le code dans src/models/components/segmentation_models.py. Les fonctions de perte sont définies dans src/config/loss.py et les schedulers dans src/config/scheduling.py. En ce qui concerne les annotations, cela se joue dans le dépot de preprocessing\n\n\n\nLe script src/train.py intègre déjà MLflow, et chaque expérimentation est automatiquement enregistrée et visualisable via l’interface graphique MLflow.\nLors de l’exécution d’une expérimentation, assurez-vous que la variable d’environnement MLFLOW_TRACKING_URI est correctement définie afin que les logs soient stockés au bon endroit. Grâce à mlflow.pytorch.autolog(), les principaux éléments (paramètres, métriques, artefacts, etc.) sont logués automatiquement. Si besoin, vous pouvez désactiver l’autologging pour enregistrer manuellement uniquement les informations jugées essentielles.\nUne fois vos expérimentations réalisées, vous pouvez les comparer facilement en les sélectionnant dans l’interface puis en cliquant sur Compare. MLflow vous permet alors d’analyser visuellement les métriques obtenues en fonction des hyperparamètres utilisés.\n\n\n\n\n\n\n🔁 Promotion d’un modèle vers la production\n\n\n\nVoici la procédure pour enregistrer un modèle performant dans le Model Registry, puis le déployer :\n\nIdentifiez une expérimentation satisfaisante, puis cliquez sur le nom du run associé pour accéder à ses détails.\nCliquez sur Register model pour enregistrer le modèle.\nChoisissez le registre approprié (Segmentation ou Segmentation-multiclass) ou créez un nouveau registre si nécessaire.\nAjoutez un tag et/ou un alias pour votre modèle. L’alias peut être utilisé, comme la version, pour charger le modèle depuis le Model Registry.\nRendez-vous sur le dépôt GitOps (ou clonez-le si ce n’est pas déjà fait).\nModifiez les lignes appropriées pour indiquer le nom et la version du modèle à déployer, puis effectuez un commit.\nConnectez-vous à ArgoCD et vérifiez que l’application satellite-images-api a bien été mise à jour. Sinon, cliquez sur Refresh.\n\n\n\n\n\n\n\n\n\n🛠️ Améliorations techniques possibles\n\n\n\nAmélioration technique sont envisageables :\n\nAjouter une signature du modèle MLflow\nAdapter le parsing des listes pour simplifier le CLI.\nUtiliser *args et **kwargs pour réduire le nombre de paramètres de la fonction.",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Entraînement d'un modèle"
    ]
  },
  {
    "objectID": "src/documentation/sections/entrainement.html#démarrage-rapide",
    "href": "src/documentation/sections/entrainement.html#démarrage-rapide",
    "title": "Entraînement d’un modèle",
    "section": "",
    "text": "git clone https://github.com/InseeFrLab/satellite-images-train.git\ncd satellite-images-train\nuv sync\nuv run pre-commit install\n\n\n\nDéfinissez les paramètres d’entraînement puis exécutez :\nbash bash/mlflow-run.sh\nL’ensemble de l’exécution sera automatiquement enregistré dans MLflow.\n\n\n\n\nMettez à jour les paramètres dans argo-workflows/train-workflow.yaml argo-workflows/train-workflow.yaml.\nSoumettez le workflow via l’interface CLI ou l’interface graphique Argo en copier/collant le template:\n\nargo submit argo-workflows/train-workflow.yaml",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Entraînement d'un modèle"
    ]
  },
  {
    "objectID": "src/documentation/sections/entrainement.html#configuration-du-modèle",
    "href": "src/documentation/sections/entrainement.html#configuration-du-modèle",
    "title": "Entraînement d’un modèle",
    "section": "",
    "text": "Le pipeline d’entraînement est construit avec PyTorch et conçu pour être flexible :\n\nArchitectures : deeplabv3, segformer-b[0–5], single_class_deeplabv3\nFonctions de perte: Cross-Entropy (avec différentes variantes), BCE, BCE avec logits\nSchedulers: reduce_on_plateau, one_cycle, etc.\nSources des labels: BDTOPO, COSIA ou autres.\n\nDe nouveaux modèles peuvent être implémenter en rajoutant le code dans src/models/components/segmentation_models.py. Les fonctions de perte sont définies dans src/config/loss.py et les schedulers dans src/config/scheduling.py. En ce qui concerne les annotations, cela se joue dans le dépot de preprocessing",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Entraînement d'un modèle"
    ]
  },
  {
    "objectID": "src/documentation/sections/entrainement.html#lutilisation-de-mlflow",
    "href": "src/documentation/sections/entrainement.html#lutilisation-de-mlflow",
    "title": "Entraînement d’un modèle",
    "section": "",
    "text": "Le script src/train.py intègre déjà MLflow, et chaque expérimentation est automatiquement enregistrée et visualisable via l’interface graphique MLflow.\nLors de l’exécution d’une expérimentation, assurez-vous que la variable d’environnement MLFLOW_TRACKING_URI est correctement définie afin que les logs soient stockés au bon endroit. Grâce à mlflow.pytorch.autolog(), les principaux éléments (paramètres, métriques, artefacts, etc.) sont logués automatiquement. Si besoin, vous pouvez désactiver l’autologging pour enregistrer manuellement uniquement les informations jugées essentielles.\nUne fois vos expérimentations réalisées, vous pouvez les comparer facilement en les sélectionnant dans l’interface puis en cliquant sur Compare. MLflow vous permet alors d’analyser visuellement les métriques obtenues en fonction des hyperparamètres utilisés.\n\n\n\n\n\n\n🔁 Promotion d’un modèle vers la production\n\n\n\nVoici la procédure pour enregistrer un modèle performant dans le Model Registry, puis le déployer :\n\nIdentifiez une expérimentation satisfaisante, puis cliquez sur le nom du run associé pour accéder à ses détails.\nCliquez sur Register model pour enregistrer le modèle.\nChoisissez le registre approprié (Segmentation ou Segmentation-multiclass) ou créez un nouveau registre si nécessaire.\nAjoutez un tag et/ou un alias pour votre modèle. L’alias peut être utilisé, comme la version, pour charger le modèle depuis le Model Registry.\nRendez-vous sur le dépôt GitOps (ou clonez-le si ce n’est pas déjà fait).\nModifiez les lignes appropriées pour indiquer le nom et la version du modèle à déployer, puis effectuez un commit.\nConnectez-vous à ArgoCD et vérifiez que l’application satellite-images-api a bien été mise à jour. Sinon, cliquez sur Refresh.\n\n\n\n\n\n\n\n\n\n🛠️ Améliorations techniques possibles\n\n\n\nAmélioration technique sont envisageables :\n\nAjouter une signature du modèle MLflow\nAdapter le parsing des listes pour simplifier le CLI.\nUtiliser *args et **kwargs pour réduire le nombre de paramètres de la fonction.",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Entraînement d'un modèle"
    ]
  },
  {
    "objectID": "src/documentation/sections/inference.html",
    "href": "src/documentation/sections/inference.html",
    "title": "Inférence du modèle et mise à disposition des résultats",
    "section": "",
    "text": "L’API, développée avec FastAPI, est déployée sur SSPCloud à l’adresse suivante : https://satellite-images-inference.lab.sspcloud.fr/. Elle propose trois endpoints :\n\nGET /predict_image — Prédiction d’une image individuelle stockée sur S3.\nGET /predict_cluster — Prédiction sur un îlot identifié par son code (peut inclure plusieurs images).\nGET /predict_bbox — Prédiction sur une bounding box définie par des coordonnées GPS (peut inclure plusieurs images).\n\nLe code associé à l’API est accessible via le dépôt d’inférence dans le dossier api/.\nUn système de cache est en place pour éviter les redondances de calcul sur une même image.\n\n\n\n\n\n\n⚠️ Limites actuelles de l’API :\n\n\n\n\nLes prédictions en batch ne sont pas possibles directement (elles doivent être séquentielles) puisque seuls des endpoints GET sont disponibles.\nCertaines opérations pourraient être asynchrones pour améliorer les performances.\nL’API reproduit le preprocessing, idéalement, il faudrait wrapper tout dans un modèle MLFlow et donc créer une custom class lors de l’entraînement.\nC’est pas un problème de l’API en tant que tel mais comment on fait les appels via make_predictions_from_api.py, il faudrait forcer l’arrêt des requêtes quand il y a eu une déconnexion côté client (Timeout/KeyboardInterrupt etc.).\nIdéalement il faudrait réduire la taille de l’image. Elle contient toutes les lib cuda alors qu’on fait l’inférence sur CPU.\n\n\n\n\n\n\n\n\n\nComment faire une montée de version de l’API\n\n\n\n\nVous développez vos nouvelles fonctionnalités dans le code de l’api (dossier api/ du dépôt d’inférence).\nUne fois que vous êtes satisfaits de votre code et que vous l’avez testé localement, vous pouvez créer un tag avec la bonne version (e.g vX.X.X) et push le tag vers Github.\nUne fois le tag pushed, cela va déclencher une Action sur Github qui va construire une nouvelle image avec votre nouvelle API, en lui associant le tag que vous avez défini.\nAllez sur le dépot GitOps et modifiez le manifeste kubernetes de déploiement de l’API. Notamment, changez la version de l’image à utiliser.\nArgoCD, qui scanne le dépôt GitOps va automatiquement détecter le changement et déploier la nouvelle version de l’API. Si vous êtes pressés, vous pouvez cliquer sur “Refresh” pour forcer ArgoCD à scanner le dépôt GitOps immédiatement.\n\n\n\n\n\n\n\n\nAfin de réaliser des prédictions sur des images, il est nécessaire de les stocker d’une manière structurée dans le S3 du projet sur le SSPCloud. En effet, l’API pour réaliser la prédiction d’une image il va directement la chercher sur le S3, ce qu’on lui donne n’est que le chemin pour y accéder. Pour savoir comment récupérer et stocker de nouvelles images, veuillez vous référer à la Section Acquisition.\n\n\n\nAfin d’obtenir rapidement une image concernant une zone géographique spécifique nous avons créé un fichier qui indexe les fichiers .tif à une certaine géométrie. Ainsi, sans ouvrir l’image en question, il nous est possible de déterminer qu’elle zone elle couvre. Ce fichier est utilisé des lors que l’on souhaite utiliser les endpoints /predict_cluster et /predict_bbox. Pour mettre à jour ce fichier qui est un parquet partitionné par le département et l’année il suffit d’exécuter le script build_filename_to_polygons.py. Ce script va détecter toutes les images qui ne sont pas encore indexée dans le fichier filename-to-polygons.parquet, les ouvrir toutes une à une pour déterminer leur bounding box et enregistrer le fichier à jour.\n\n\n\nPour prédire la couverture du sol sur un échantillon d’images il est nécessaire d’utiliser l’endpoint /predict_image. Le script make_predictions_from_api.py permet de réaliser les prédictions pour le millésime d’un département donné. Il réalise de manière asynchrone des appels à l’API.\n\n\n\n\n\n\nTip\n\n\n\nLorsque vous lancez une prédiction sur un grand nombre d’image, il est conseillé d’augmenter le nombre de replicas de l’API afin de réduire sensiblement le temps de calcul. Notez également que l’API n’implémente pas pour le moment de prédiction par batch , ce qui pourrait également améliorer considérablement les temps de calcul (sous réserve de la mémoire disponible)\n\n\nIl est recommandé de réaliser les prédictions à l’aide d’Argo Workflow en utilisant le template predict-workflows.yaml. Celui-ci, en plus de réaliser les prédictions, va directemment transférer les images et les prédictions dans le PVC du Geoserver afin de les mettre à disposition.\n\n\n\n\nUne fois les prédictions faites, il est important de les intégrer au Geoserver (demander les identifiants à l’équipe).\n\n\nUn remplissage dans le pvc du GeoServer se fait directement lors de l’inférence via le template ArgoWorkflow.\nCette étape consiste à stocker les images Pléiades et les prédictions dans le GeoServer.\n\n\n\nIl est important de créer un entrepôt et une couche pour utiliser les données sous forme de flux WMS dans la webapp. Pour l’instant, cette étape est manuelle : nous n’avons pas trouvé de méthode automatique.\n\n\n\n\nEntrepôt\n\nMenu Données &gt; Entrepôts (à gauche)\n\nCliquez sur + Ajouter un nouvel entrepôt\n\nChoisir ImageMosaic\n\nname = &lt;DEP&gt;_&lt;YEAR&gt;\n\nParcourir le dossier PLEIADES/&lt;DEP&gt;/&lt;YEAR&gt;\n\n➡️ Sauvegarder\n\nCouche\n\nMenu Données &gt; Couches\n\nCliquez sur + Ajouter une nouvelle couche\n\nSélectionner l’entrepôt créé\n\nname = &lt;DEP&gt;_&lt;YEAR&gt;, title = &lt;YEAR&gt;\n\n➡️ Sauvegarder\n\n\n\n\n\n\nEntrepôt\n\nMenu Données &gt; Entrepôts\n\nCliquez sur + Ajouter un nouvel entrepôt\n\nChoisir Geopackage\n\nname = &lt;DEP&gt;_PREDICTIONS_&lt;YEAR&gt;\n\nParcourir le fichier :\nPREDICTIONS/PLEIADES/&lt;DEP&gt;/&lt;YEAR&gt;/Segmentation-multiclasse/1/predictions.gpkg\n\n➡️ Sauvegarder\n\nCouche\n\nMenu Données &gt; Couches\n\nCliquez sur + Ajouter une nouvelle couche\n\nSélectionner l’entrepôt créé\n\nname = &lt;DEP&gt;_PREDICTIONS_&lt;YEAR&gt;, title = &lt;DEP&gt;_PREDICTIONS_&lt;YEAR&gt;\n\nDans l’onglet Emprises :\n\nCliquer sur Basées sur les données, puis Calculer depuis les emprises natives\n\n\nDans Publication &gt; Style par défaut : dirag:style_multiclass\n\n➡️ Sauvegarder\n\n\n⚠️ Vérification\nPour vérifier que tout s’est bien passé :\nMenu Prévisualisation de la couche (à gauche) → Cliquer sur OpenLayers de la couche souhaitée pour la prévisualiser.\n\n\n\n\nUne fois les nouvelles couches créées, il faut les intégrer dans la webapp CRaTT :\n\nCloner le dépôt Git\n\nModifier le code pour ajouter le nouveau couple Département / Année :\n\nDans components/config.js\n\nEt dans utils/config.js\n\n\n💡 Le git push déclenche automatiquement un rebuild du site. Les nouvelles couches seront visibles après quelques minutes (une fois que l’action GitHub est terminée).",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Mise à disposition des résultats"
    ]
  },
  {
    "objectID": "src/documentation/sections/inference.html#lapi-dinférence",
    "href": "src/documentation/sections/inference.html#lapi-dinférence",
    "title": "Inférence du modèle et mise à disposition des résultats",
    "section": "",
    "text": "L’API, développée avec FastAPI, est déployée sur SSPCloud à l’adresse suivante : https://satellite-images-inference.lab.sspcloud.fr/. Elle propose trois endpoints :\n\nGET /predict_image — Prédiction d’une image individuelle stockée sur S3.\nGET /predict_cluster — Prédiction sur un îlot identifié par son code (peut inclure plusieurs images).\nGET /predict_bbox — Prédiction sur une bounding box définie par des coordonnées GPS (peut inclure plusieurs images).\n\nLe code associé à l’API est accessible via le dépôt d’inférence dans le dossier api/.\nUn système de cache est en place pour éviter les redondances de calcul sur une même image.\n\n\n\n\n\n\n⚠️ Limites actuelles de l’API :\n\n\n\n\nLes prédictions en batch ne sont pas possibles directement (elles doivent être séquentielles) puisque seuls des endpoints GET sont disponibles.\nCertaines opérations pourraient être asynchrones pour améliorer les performances.\nL’API reproduit le preprocessing, idéalement, il faudrait wrapper tout dans un modèle MLFlow et donc créer une custom class lors de l’entraînement.\nC’est pas un problème de l’API en tant que tel mais comment on fait les appels via make_predictions_from_api.py, il faudrait forcer l’arrêt des requêtes quand il y a eu une déconnexion côté client (Timeout/KeyboardInterrupt etc.).\nIdéalement il faudrait réduire la taille de l’image. Elle contient toutes les lib cuda alors qu’on fait l’inférence sur CPU.\n\n\n\n\n\n\n\n\n\nComment faire une montée de version de l’API\n\n\n\n\nVous développez vos nouvelles fonctionnalités dans le code de l’api (dossier api/ du dépôt d’inférence).\nUne fois que vous êtes satisfaits de votre code et que vous l’avez testé localement, vous pouvez créer un tag avec la bonne version (e.g vX.X.X) et push le tag vers Github.\nUne fois le tag pushed, cela va déclencher une Action sur Github qui va construire une nouvelle image avec votre nouvelle API, en lui associant le tag que vous avez défini.\nAllez sur le dépot GitOps et modifiez le manifeste kubernetes de déploiement de l’API. Notamment, changez la version de l’image à utiliser.\nArgoCD, qui scanne le dépôt GitOps va automatiquement détecter le changement et déploier la nouvelle version de l’API. Si vous êtes pressés, vous pouvez cliquer sur “Refresh” pour forcer ArgoCD à scanner le dépôt GitOps immédiatement.",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Mise à disposition des résultats"
    ]
  },
  {
    "objectID": "src/documentation/sections/inference.html#réaliser-des-prédictions-sur-des-images",
    "href": "src/documentation/sections/inference.html#réaliser-des-prédictions-sur-des-images",
    "title": "Inférence du modèle et mise à disposition des résultats",
    "section": "",
    "text": "Afin de réaliser des prédictions sur des images, il est nécessaire de les stocker d’une manière structurée dans le S3 du projet sur le SSPCloud. En effet, l’API pour réaliser la prédiction d’une image il va directement la chercher sur le S3, ce qu’on lui donne n’est que le chemin pour y accéder. Pour savoir comment récupérer et stocker de nouvelles images, veuillez vous référer à la Section Acquisition.\n\n\n\nAfin d’obtenir rapidement une image concernant une zone géographique spécifique nous avons créé un fichier qui indexe les fichiers .tif à une certaine géométrie. Ainsi, sans ouvrir l’image en question, il nous est possible de déterminer qu’elle zone elle couvre. Ce fichier est utilisé des lors que l’on souhaite utiliser les endpoints /predict_cluster et /predict_bbox. Pour mettre à jour ce fichier qui est un parquet partitionné par le département et l’année il suffit d’exécuter le script build_filename_to_polygons.py. Ce script va détecter toutes les images qui ne sont pas encore indexée dans le fichier filename-to-polygons.parquet, les ouvrir toutes une à une pour déterminer leur bounding box et enregistrer le fichier à jour.\n\n\n\nPour prédire la couverture du sol sur un échantillon d’images il est nécessaire d’utiliser l’endpoint /predict_image. Le script make_predictions_from_api.py permet de réaliser les prédictions pour le millésime d’un département donné. Il réalise de manière asynchrone des appels à l’API.\n\n\n\n\n\n\nTip\n\n\n\nLorsque vous lancez une prédiction sur un grand nombre d’image, il est conseillé d’augmenter le nombre de replicas de l’API afin de réduire sensiblement le temps de calcul. Notez également que l’API n’implémente pas pour le moment de prédiction par batch , ce qui pourrait également améliorer considérablement les temps de calcul (sous réserve de la mémoire disponible)\n\n\nIl est recommandé de réaliser les prédictions à l’aide d’Argo Workflow en utilisant le template predict-workflows.yaml. Celui-ci, en plus de réaliser les prédictions, va directemment transférer les images et les prédictions dans le PVC du Geoserver afin de les mettre à disposition.",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Mise à disposition des résultats"
    ]
  },
  {
    "objectID": "src/documentation/sections/inference.html#geoserver",
    "href": "src/documentation/sections/inference.html#geoserver",
    "title": "Inférence du modèle et mise à disposition des résultats",
    "section": "",
    "text": "Une fois les prédictions faites, il est important de les intégrer au Geoserver (demander les identifiants à l’équipe).\n\n\nUn remplissage dans le pvc du GeoServer se fait directement lors de l’inférence via le template ArgoWorkflow.\nCette étape consiste à stocker les images Pléiades et les prédictions dans le GeoServer.\n\n\n\nIl est important de créer un entrepôt et une couche pour utiliser les données sous forme de flux WMS dans la webapp. Pour l’instant, cette étape est manuelle : nous n’avons pas trouvé de méthode automatique.\n\n\n\n\nEntrepôt\n\nMenu Données &gt; Entrepôts (à gauche)\n\nCliquez sur + Ajouter un nouvel entrepôt\n\nChoisir ImageMosaic\n\nname = &lt;DEP&gt;_&lt;YEAR&gt;\n\nParcourir le dossier PLEIADES/&lt;DEP&gt;/&lt;YEAR&gt;\n\n➡️ Sauvegarder\n\nCouche\n\nMenu Données &gt; Couches\n\nCliquez sur + Ajouter une nouvelle couche\n\nSélectionner l’entrepôt créé\n\nname = &lt;DEP&gt;_&lt;YEAR&gt;, title = &lt;YEAR&gt;\n\n➡️ Sauvegarder\n\n\n\n\n\n\nEntrepôt\n\nMenu Données &gt; Entrepôts\n\nCliquez sur + Ajouter un nouvel entrepôt\n\nChoisir Geopackage\n\nname = &lt;DEP&gt;_PREDICTIONS_&lt;YEAR&gt;\n\nParcourir le fichier :\nPREDICTIONS/PLEIADES/&lt;DEP&gt;/&lt;YEAR&gt;/Segmentation-multiclasse/1/predictions.gpkg\n\n➡️ Sauvegarder\n\nCouche\n\nMenu Données &gt; Couches\n\nCliquez sur + Ajouter une nouvelle couche\n\nSélectionner l’entrepôt créé\n\nname = &lt;DEP&gt;_PREDICTIONS_&lt;YEAR&gt;, title = &lt;DEP&gt;_PREDICTIONS_&lt;YEAR&gt;\n\nDans l’onglet Emprises :\n\nCliquer sur Basées sur les données, puis Calculer depuis les emprises natives\n\n\nDans Publication &gt; Style par défaut : dirag:style_multiclass\n\n➡️ Sauvegarder\n\n\n⚠️ Vérification\nPour vérifier que tout s’est bien passé :\nMenu Prévisualisation de la couche (à gauche) → Cliquer sur OpenLayers de la couche souhaitée pour la prévisualiser.",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Mise à disposition des résultats"
    ]
  },
  {
    "objectID": "src/documentation/sections/inference.html#webapp-cratt",
    "href": "src/documentation/sections/inference.html#webapp-cratt",
    "title": "Inférence du modèle et mise à disposition des résultats",
    "section": "",
    "text": "Une fois les nouvelles couches créées, il faut les intégrer dans la webapp CRaTT :\n\nCloner le dépôt Git\n\nModifier le code pour ajouter le nouveau couple Département / Année :\n\nDans components/config.js\n\nEt dans utils/config.js\n\n\n💡 Le git push déclenche automatiquement un rebuild du site. Les nouvelles couches seront visibles après quelques minutes (une fois que l’action GitHub est terminée).",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Mise à disposition des résultats"
    ]
  },
  {
    "objectID": "src/todo/index.html",
    "href": "src/todo/index.html",
    "title": "TODO",
    "section": "",
    "text": "Faire un script de transformation des des images de taille (x, y) en (n, n) avec GDAL\nIndustrialiser sur la nouvelle webapp tous les départements (priorité Guyane/St Martin) ✅\n\nUtiliser les labels de COSIA pour entrainer (finetuner) un nouveau modèle ✅\n\nCache les predictions en terme de probabilité plutot que masque binaire ✅\n\nMettre les prédictions multiclasses sur la webapp ✅\n\nRetravailler les fonctionnalités des cartes de la webapp\nRetélécharger Guyane via SEAS, utiliser les masques nuages pour faire le découpage (prioriser en fonction de la date)\nInférence sur nouveau découpage Guyane\n\nUtiliser une bdd externe pour flaguer les zones de bâti non résidentielles\n\nDepuis la webapp, pouvoir télécharger le tableau des statistiques\n\nSélectionner un ilot produit un graphique d’évolution du bâti sur les millésimes disponibles\n\nMettre les couches RIL sur la webapp\n\nRécupérer les annotations de destructions post cyclone Chido produites par Copernicus pour les afficher sur la webapp + les utiliser comme données de validation\n\nProduire les polygones destructions/constructions de bâti en comparant les logits plutôt que les prédictions de classe + recalculer les statistiques d’évolution en conséquence –&gt; heat map\n\nAfficher la carte plein écran sur CRaTT\n\nFaire un travail sur les prédictions pour merge les pred car on voit les délimitations des patchs envoyés à l’API pour l’inférence (cf travail fait pendant le stage l’année dernière)\n\nOutil pour valider les annotations et faire un jeu de test gold-standard ?\n\nPublier le modèle sur Hugging Face\n\n\n\n\n\n\n\nPour enquête carto :\n\nêtre capable de déterminer les changements prioritaires à regarder et cohérent (pas des nuages) / Stockage des ilots controlés\nfaire le use case mayotte sur 5 ans d’intervalle\n\nApplication de mise à dispo de point gpx avec fond données satellites\n\n\n\n\n\nComparaison entre l’EAR/RIL et nos surfaces estimés / estimation de population basé sur les surfaces prédites\nPréparation d’un papier pour les JMS avec la DMTR. En lien avec les récents travaux sur Mayotte pour la DMTR et la préparation du futur recensement exhaustif de 2026. Ce sera un papier méthodologique sur le projet images satellites, illustré du cas d’usage de la DMTR (aide au recensement avec de la cartographie et/ou statistiques publiques, tout cela grâce aux prédictions sur images satellites).\n\nContact avec Julie Djiriguian pour présenter nos travaux afin de les aider à préparer l’enquête cartographique 2025 en vue du recensement exhaustif de Mayotte 2026.\n\n\n\n\n\n\nfaire un DT Insee et voir avec CP si ca la branche\nFaire la documentation du projet\nmise à disposition du modèle CoSIA via l’API et faire pub aux européens"
  },
  {
    "objectID": "src/todo/index.html#techos",
    "href": "src/todo/index.html#techos",
    "title": "TODO",
    "section": "",
    "text": "Faire un script de transformation des des images de taille (x, y) en (n, n) avec GDAL\nIndustrialiser sur la nouvelle webapp tous les départements (priorité Guyane/St Martin) ✅\n\nUtiliser les labels de COSIA pour entrainer (finetuner) un nouveau modèle ✅\n\nCache les predictions en terme de probabilité plutot que masque binaire ✅\n\nMettre les prédictions multiclasses sur la webapp ✅\n\nRetravailler les fonctionnalités des cartes de la webapp\nRetélécharger Guyane via SEAS, utiliser les masques nuages pour faire le découpage (prioriser en fonction de la date)\nInférence sur nouveau découpage Guyane\n\nUtiliser une bdd externe pour flaguer les zones de bâti non résidentielles\n\nDepuis la webapp, pouvoir télécharger le tableau des statistiques\n\nSélectionner un ilot produit un graphique d’évolution du bâti sur les millésimes disponibles\n\nMettre les couches RIL sur la webapp\n\nRécupérer les annotations de destructions post cyclone Chido produites par Copernicus pour les afficher sur la webapp + les utiliser comme données de validation\n\nProduire les polygones destructions/constructions de bâti en comparant les logits plutôt que les prédictions de classe + recalculer les statistiques d’évolution en conséquence –&gt; heat map\n\nAfficher la carte plein écran sur CRaTT\n\nFaire un travail sur les prédictions pour merge les pred car on voit les délimitations des patchs envoyés à l’API pour l’inférence (cf travail fait pendant le stage l’année dernière)\n\nOutil pour valider les annotations et faire un jeu de test gold-standard ?\n\nPublier le modèle sur Hugging Face"
  },
  {
    "objectID": "src/todo/index.html#insee",
    "href": "src/todo/index.html#insee",
    "title": "TODO",
    "section": "",
    "text": "Pour enquête carto :\n\nêtre capable de déterminer les changements prioritaires à regarder et cohérent (pas des nuages) / Stockage des ilots controlés\nfaire le use case mayotte sur 5 ans d’intervalle\n\nApplication de mise à dispo de point gpx avec fond données satellites\n\n\n\n\n\nComparaison entre l’EAR/RIL et nos surfaces estimés / estimation de population basé sur les surfaces prédites\nPréparation d’un papier pour les JMS avec la DMTR. En lien avec les récents travaux sur Mayotte pour la DMTR et la préparation du futur recensement exhaustif de 2026. Ce sera un papier méthodologique sur le projet images satellites, illustré du cas d’usage de la DMTR (aide au recensement avec de la cartographie et/ou statistiques publiques, tout cela grâce aux prédictions sur images satellites).\n\nContact avec Julie Djiriguian pour présenter nos travaux afin de les aider à préparer l’enquête cartographique 2025 en vue du recensement exhaustif de Mayotte 2026."
  },
  {
    "objectID": "src/todo/index.html#diffusion-des-résultats",
    "href": "src/todo/index.html#diffusion-des-résultats",
    "title": "TODO",
    "section": "",
    "text": "faire un DT Insee et voir avec CP si ca la branche\nFaire la documentation du projet\nmise à disposition du modèle CoSIA via l’API et faire pub aux européens"
  },
  {
    "objectID": "src/documentation/sections/pipeline.html#architecture-du-projet",
    "href": "src/documentation/sections/pipeline.html#architecture-du-projet",
    "title": "Projet Données Satellites",
    "section": "Architecture du projet 🧩",
    "text": "Architecture du projet 🧩",
    "crumbs": [
      "Accueil",
      "Navigation",
      "Pipeline du projet"
    ]
  },
  {
    "objectID": "src/seminaire-dirag-video/index.html",
    "href": "src/seminaire-dirag-video/index.html",
    "title": "Vidéo du séminaire du 28 mai 2024 à la Dirag",
    "section": "",
    "text": "Vidéo du séminaire du 28 mai 2024 à la Dirag"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#project-overview",
    "href": "src/aiml4os-wp7/index.html#project-overview",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Project Overview",
    "text": "Project Overview\n\nSatellite imagery exploration for official statistics, initiated through academic challenge (2022)\nOperational implementation in French overseas territories\nPart of European strategy (Warsaw Memorandum)"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#applications-in-official-statistics",
    "href": "src/aiml4os-wp7/index.html#applications-in-official-statistics",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Applications in Official Statistics",
    "text": "Applications in Official Statistics\n\nCartographic survey optimization:\n\nIdentification of priority areas for field operations\nDetection of building changes between surveys\nTemporal comparison using historical and recent imagery\n\nBuilding stock monitoring:\n\nAutomated change detection\nLand use evolution\nSupport for population estimates in overseas territories"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#focus-on-mayotte-and-french-guiana",
    "href": "src/aiml4os-wp7/index.html#focus-on-mayotte-and-french-guiana",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Focus on Mayotte and French Guiana",
    "text": "Focus on Mayotte and French Guiana\n\nCritical context:\n\nLocal authorities questioning official statistics\nRapid urban development\nChallenging field conditions\n\nSatellite data as supporting evidence:\n\nIndependent source of information\nContinuous territorial monitoring\nTransparent methodology"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#semantic-segmentation",
    "href": "src/aiml4os-wp7/index.html#semantic-segmentation",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Semantic Segmentation",
    "text": "Semantic Segmentation\n\nPleiades © CNES_2022, Distribution AIRBUS DS"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#training-a-segmentation-model",
    "href": "src/aiml4os-wp7/index.html#training-a-segmentation-model",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Training a Segmentation Model",
    "text": "Training a Segmentation Model\n\nModel trained to perform automatic segmentation from annotated examples. Requirements:\n\nCollection of satellite images\nProduction of annotations (building footprints)\n\nModel learns to reproduce annotations from images, with the goal to generalize to new images"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#from-segmentation-to-change-detection",
    "href": "src/aiml4os-wp7/index.html#from-segmentation-to-change-detection",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "From Segmentation to Change Detection",
    "text": "From Segmentation to Change Detection"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#methodology-details",
    "href": "src/aiml4os-wp7/index.html#methodology-details",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Methodology Details",
    "text": "Methodology Details\n\nModel architecture:\n\nSegFormer backbone\nTransformer-based encoder\nLightweight decoder"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#satellite-imagery-key-features",
    "href": "src/aiml4os-wp7/index.html#satellite-imagery-key-features",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Satellite Imagery: Key Features",
    "text": "Satellite Imagery: Key Features\n\nMultiple spectral bands beyond RGB (e.g., infrared)\nGeoreferenced data: each pixel has specific coordinates\nMain characteristics:\n\nSpatial resolution\nAcquisition frequency\nSpectral resolution\nGeographic coverage"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#available-data-sources-pleiades",
    "href": "src/aiml4os-wp7/index.html#available-data-sources-pleiades",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Available Data Sources (PLEIADES)",
    "text": "Available Data Sources (PLEIADES)\nPléiades (Very High Resolution)\n\n0.5m × 0.5m spatial resolution\n3 bands (RGB)\nFree archives, on-demand acquisition (6-8 months for a department)\nImage size: 1km² (2000 × 2000 pixels)"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#available-data-sources-sentinel-2",
    "href": "src/aiml4os-wp7/index.html#available-data-sources-sentinel-2",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Available Data Sources (Sentinel-2)",
    "text": "Available Data Sources (Sentinel-2)\nSentinel-2 (High Resolution)\n\n10m × 10m spatial resolution\n13 spectral bands\n5-day revisit time, free access\nImage size: 6.25 km² (250 × 250)"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#reference-data-bdtopo",
    "href": "src/aiml4os-wp7/index.html#reference-data-bdtopo",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Reference Data (BDTOPO)",
    "text": "Reference Data (BDTOPO)\n\nBuilding footprints as vector polygons\nBased on IGN aerial photography\nUsed as training data despite temporal misalignment with Pléiades imagery"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#interactive-visualization-tool",
    "href": "src/aiml4os-wp7/index.html#interactive-visualization-tool",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Interactive Visualization Tool",
    "text": "Interactive Visualization Tool\nAccess the application: Click here\n\nAdministrative-level monitoring of building changes:\n\nSelection by administrative units (municipalities, districts)\nQuality control of detected changes\n\nKey features:\n\nSide-by-side temporal comparison\nStatistical indicators by area\nInteractive visual validation\n\n\n\n\nDecided to build a tiny webapp … but we are datascientists be indulgent\nWe computed building areas from our predictions this we get binary value for each pixel and aggregated by admin level\n\n⚠️ Disclaimer : This is a an early stage of our application. 0 check or data quality process have been done.\n\nStandard leaflet map with open Street map layer show Pleiades 2023\n\n97611 0332 : nuages in 2022\n97610ﾠ0608 : different methodology of blurring for prison\n97611 0237 : Our use case : detect building changes in precarious areas"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#technical-environment",
    "href": "src/aiml4os-wp7/index.html#technical-environment",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Technical Environment",
    "text": "Technical Environment\n\nCloud-native architecture (SSPCloud platform)\nModern tech stack: Kubernetes, Docker, MLFlow, React\nAutomated workflows for reproducibility\nContinuous deployment practices"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#processing-pipeline",
    "href": "src/aiml4os-wp7/index.html#processing-pipeline",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Processing Pipeline",
    "text": "Processing Pipeline\n\n\n\n\n\n\n\n\n\n\n\nNeed for standardisation of acquisition of data =&gt; for now rudimentary. Also need dated images but also in due time without clouds and same methodology =&gt; challenge of Pleaides\nStep for training. Clouds removals/ balancing datasets, labeling and splitting\npytorch with pre trained model from HF. Need GPU\nBuild API : predict images, cluster or bbox and compute building area statistics\nDéploying Geoserver and a web application\nColleagues of Insee uses or results to make their statistics"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#application-architecture",
    "href": "src/aiml4os-wp7/index.html#application-architecture",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Application Architecture",
    "text": "Application Architecture\n\n\nGeoserver : dynamically stores satellite images"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#technical-implementation",
    "href": "src/aiml4os-wp7/index.html#technical-implementation",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Technical Implementation",
    "text": "Technical Implementation\n\nComplex technical environment due to:\n\nNon-traditional data processing\nLarge data volumes\nHigh computational needs\nReproducibility requirements"
  },
  {
    "objectID": "src/aiml4os-wp7/index.html#challenges-perspectives",
    "href": "src/aiml4os-wp7/index.html#challenges-perspectives",
    "title": "Exploratory Work with Satellite Data: Results Assessment",
    "section": "Challenges & Perspectives",
    "text": "Challenges & Perspectives\n\nHigh maintenance costs due to technical complexity\nNeed for specialized skills\nPromising results for cartographic survey support\nPotential improvements identified for each pipeline stage"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#origine-du-projet",
    "href": "src/seminaire-dirag/index.html#origine-du-projet",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Origine du projet",
    "text": "Origine du projet\n\nDans le cadre du stage de Quentin Chabennet en 2022, participation au Challenge Data “Land cover predictive modeling from satellite images”\nSSM Agriculture: travail avec le Centre d’études spatiales de la biosphère (Cesbio). Comparaison de la carte d’occupation du sol issue de l’enquête Teruti avec une carte construite avec des données de télédétection\nEn Guyane, fonds de carte issus de données Pléiades utilisés pour la collecte\nDiscussion sur la possibilité d’utiliser de l’imagerie satellite pour faciliter l’organisation de l’enquête cartographique en Guyane et à Mayotte"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#une-source-de-données-à-fort-potentiel",
    "href": "src/seminaire-dirag/index.html#une-source-de-données-à-fort-potentiel",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Une source de données à fort potentiel",
    "text": "Une source de données à fort potentiel\n\nEn théorie, observation de tout le territoire quasiment en temps réel\nSentinel-2 : données haute résolution en accès libre à haute fréquence temporelle. Un même territoire est couvert environ tous les 5 jours\nUne grande communauté utilise ces données, ce qui donne lieu à la publication de contenu open-source (détection de nuages, etc.)"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#une-source-de-données-à-fort-potentiel-1",
    "href": "src/seminaire-dirag/index.html#une-source-de-données-à-fort-potentiel-1",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Une source de données à fort potentiel",
    "text": "Une source de données à fort potentiel\n\nPléiades : données très haute résolution. Archives disponibles gratuitement pour l’Insee, et possibilité de faire des commandes (tasking), gratuites sous un certain quota"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#utilisation-pour-la-statistique-publique",
    "href": "src/seminaire-dirag/index.html#utilisation-pour-la-statistique-publique",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Utilisation pour la statistique publique",
    "text": "Utilisation pour la statistique publique\n\nMémorandum de Varsovie adopté par le Comité du Système statistique européen, pour encourager l’utilisation des données satellites pour l’élaboration de statistiques publiques\nUtilisation en complément des sources traditionnelles pour améliorer la connaissance de l’Insee sur le bâti :\n\nEn particulier dans les DROM, facilitation de l’organisation des enquêtes cartographiques\nCartographie du bâti à un instant précis\nEtudes ponctuelles (consommation d’espace)"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#utilisation-pour-la-statistique-publique-1",
    "href": "src/seminaire-dirag/index.html#utilisation-pour-la-statistique-publique-1",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Utilisation pour la statistique publique",
    "text": "Utilisation pour la statistique publique\n\nPossibilité d’aller jusqu’à contribuer à des estimations de population ?\nNombreux acteurs intéressés : DMS (DMRG), DMTR, directions Antilles-Guyane et La Réunion-Mayotte"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#début-des-travaux",
    "href": "src/seminaire-dirag/index.html#début-des-travaux",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Début des travaux",
    "text": "Début des travaux\n\nDétection automatique de changements (apparitions, disparitions) sur le bâti dans les DROM (Mayotte)\nAppui pour l’organisation des enquêtes cartographiques :\n\nOn sélectionne les îlots concernés\nOn récupère des données satellites couvrant ces îlots à la date de la précédente enquête cartographique et des données fraîches\nA l’aide de la méthode développée, on repère les ilots avec beaucoup de nouveaux bâtiments, etc."
  },
  {
    "objectID": "src/seminaire-dirag/index.html#segmentation-sémantique",
    "href": "src/seminaire-dirag/index.html#segmentation-sémantique",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Segmentation sémantique",
    "text": "Segmentation sémantique\n\nPleiades © CNES_2022, Distribution AIRBUS DS"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#entrainement-dun-modèle-de-segmentation",
    "href": "src/seminaire-dirag/index.html#entrainement-dun-modèle-de-segmentation",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Entrainement d’un modèle de segmentation",
    "text": "Entrainement d’un modèle de segmentation\n\nOn entraîne un modèle à segmenter automatiquement à partir d’exemples annotés. Pour cela il faut :\n\nCollecter des images satellites\nProduire les annotations de ces images (emplacement des bâtiments)\n\nOn apprend au modèle à reproduire les annotations en partant des images. On espère qu’il pourra généraliser à d’autres images"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#de-segmentation-à-détection-de-changements",
    "href": "src/seminaire-dirag/index.html#de-segmentation-à-détection-de-changements",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "De segmentation à détection de changements",
    "text": "De segmentation à détection de changements"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#quest-ce-quune-image",
    "href": "src/seminaire-dirag/index.html#quest-ce-quune-image",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Qu’est-ce qu’une image ?",
    "text": "Qu’est-ce qu’une image ?\nUne image en couleurs concatène plusieurs tableaux de chiffres, un tableau pour chaque couleur Rouge (R), Vert (G), Bleu (B) :"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#une-image-satellite",
    "href": "src/seminaire-dirag/index.html#une-image-satellite",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Une image satellite",
    "text": "Une image satellite\n\nUne image satellite peut avoir d’autres couches (ou bandes) que les RGB : infrarouge par exemple\nLes images satellites contiennent des informations géographiques → chaque pixel a des coordonnées dans l’espace"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#caractéristiques-dune-image-satellite",
    "href": "src/seminaire-dirag/index.html#caractéristiques-dune-image-satellite",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Caractéristiques d’une image satellite",
    "text": "Caractéristiques d’une image satellite\nPlusieurs caractéristiques existent pour une image satellite :\n\nLa résolution spatiale\nLa fréquence d’acquisition\nLa résolution spectrale\nLa couverture géographique\n\nLa fréquence d’acquisition et la couverture géographique nous intéressent tout particulièrement ici !"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#images-satellite-à-notre-disposition",
    "href": "src/seminaire-dirag/index.html#images-satellite-à-notre-disposition",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Images satellite à notre disposition",
    "text": "Images satellite à notre disposition\n\nImages très haute résolution : Pléiades (Airbus)\nImages haute résolution : Sentinel2"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#images-pléiades",
    "href": "src/seminaire-dirag/index.html#images-pléiades",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Images Pléiades",
    "text": "Images Pléiades\n\nFréquence d’acquisition :\n\nArchives gratuites\nPayant sur demande (1,80€/km²): 6 à 8 mois pour avoir un département\n\nRésolution spectrale : 3 bandes (RGB)\nRésolution spatiale : un pixel = \\(0.5m \\times 0.5m\\)\nTaille d’une image : \\(2000 \\times 2000\\) pixels = 1km²"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#images-sentinel2",
    "href": "src/seminaire-dirag/index.html#images-sentinel2",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Images Sentinel2",
    "text": "Images Sentinel2\n\nFréquence d’acquisition : tous les 5 jours et gratuit\nRésolution spectrale : 13\nRésolution spatiale : un pixel = \\(10m \\times 10m\\)\nTaille d’une image : \\(250 \\times 250\\) = 6.25 km²"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#pléiades-vs-sentinel-2",
    "href": "src/seminaire-dirag/index.html#pléiades-vs-sentinel-2",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Pléiades vs Sentinel-2",
    "text": "Pléiades vs Sentinel-2\n\n\n\n\n\n\n\n\n\nPleiades © CNES_2022, Distribution AIRBUS DS\n\n\n\n\n\n\n\nSentinel2"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#sources-disponibles-de-localisation-de-bâtiments",
    "href": "src/seminaire-dirag/index.html#sources-disponibles-de-localisation-de-bâtiments",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Sources disponibles de localisation de bâtiments",
    "text": "Sources disponibles de localisation de bâtiments\nDeux sources d’annotations envisagées pour les bâtiments :\n\nLe RIL (INSEE)\nLa BDTOPO (IGN)"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#le-ril",
    "href": "src/seminaire-dirag/index.html#le-ril",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Le RIL",
    "text": "Le RIL\n\nAnnotation d’un bâtiment = un point qui donne l’emplacement du bâtiment (porte d’entrée ?)\nLe répertoire des immeubles localisés est une base de sondage actualisée dans les DOM par l’enquête cartographique\nAnnotations en quantité limitée : l’enquête cartographique ne met à jour qu’un cinquième des logements du RIL dans les DOM\nConcept de logement"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#exemple-dannotations-ril",
    "href": "src/seminaire-dirag/index.html#exemple-dannotations-ril",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Exemple d’annotations RIL",
    "text": "Exemple d’annotations RIL\n\nMasque RIL, Pleiades © CNES_2022, Distribution AIRBUS DS"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#la-bdtopo",
    "href": "src/seminaire-dirag/index.html#la-bdtopo",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "La BDTOPO",
    "text": "La BDTOPO\n\nAnnotation d’un bâtiment = un polygone\nElle est construite à partir de plusieurs sources, notamment à partir d’ortho-photos de l’IGN (prises de vue aériennes)\nLes éléments de la BDTOPO produite une année donnée ne sont pas datés précisément\nLa BDTOPO n’est pas synchronisée avec les images Pléiades que l’INSEE acquiert\n\nOn la retient tout de même pour annoter les images Pléiades."
  },
  {
    "objectID": "src/seminaire-dirag/index.html#exemple-dannotations-bdtopo",
    "href": "src/seminaire-dirag/index.html#exemple-dannotations-bdtopo",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Exemple d’annotations BDTOPO",
    "text": "Exemple d’annotations BDTOPO\n\nMasque BDTOPO, Pleiades © CNES_2022, Distribution AIRBUS DS"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#résultats-de-mayotte",
    "href": "src/seminaire-dirag/index.html#résultats-de-mayotte",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Résultats de Mayotte",
    "text": "Résultats de Mayotte\n\nPleiades © CNES_2022, Distribution AIRBUS DS"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#section",
    "href": "src/seminaire-dirag/index.html#section",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "",
    "text": "Prédictions originales 2023 de Mayotte et localisation des quartiers de l’île (Insee 2012), Pleiades © CNES_2022, Distribution AIRBUS DS"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#étalement-urbain",
    "href": "src/seminaire-dirag/index.html#étalement-urbain",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Étalement urbain",
    "text": "Étalement urbain\n\nPleiades © CNES_2022, Distribution AIRBUS DS"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#construction-de-logements",
    "href": "src/seminaire-dirag/index.html#construction-de-logements",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Construction de logements",
    "text": "Construction de logements\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrédictions 2023 sur fond d’image 2020 et sur fond d’image 2023, Pleiades © CNES_2022, Distribution AIRBUS DS"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#prédictions-dun-centre-ville",
    "href": "src/seminaire-dirag/index.html#prédictions-dun-centre-ville",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Prédictions d’un centre-ville",
    "text": "Prédictions d’un centre-ville\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrédictions originales 2023 d’une zone de Mayotte, Pleiades © CNES_2022, Distribution AIRBUS DS"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#imperfections-du-modèle",
    "href": "src/seminaire-dirag/index.html#imperfections-du-modèle",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Imperfections du modèle",
    "text": "Imperfections du modèle\n\n\n\nFrontières entre les images\nDélimitations imprécises\nMinuscules polygones"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#nettoyage-des-polygones",
    "href": "src/seminaire-dirag/index.html#nettoyage-des-polygones",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Nettoyage des polygones",
    "text": "Nettoyage des polygones\n\nApplication d’un buffer positif puis négatif\n\nPropriétés de lissage (arrondis)\nClôture des petites brèches dans les bâtiments\n\n\n\n\nFusion des polygones qui s’interceptent pour effacer les frontières"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#petits-polygones",
    "href": "src/seminaire-dirag/index.html#petits-polygones",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Petits polygones ?",
    "text": "Petits polygones ?\nPrésence de petits polygones (de 1m² à 10m²) : qu’en faire ?\n\nLogement décent : 9m²\nMayotte : 30% environ des logements n’ont pas accès à l’eau potable\n\nOn ne cherche pas que les logements décents :\n\nRecherche d’exhaustivité pour soutenir les enquêteurs\nObjectifs d’estimation de population (nombre de bâtiments ou surface ?)"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#petits-polygones-1",
    "href": "src/seminaire-dirag/index.html#petits-polygones-1",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Petits polygones ?",
    "text": "Petits polygones ?\n\nObservations manuelles : les petits polygones pointent souvent sur des bâtiments qui n’ont pas été repérés entièrement par l’algorithme. Ce n’est donc pas que du bruit.\n\nConclusion : dans la mesure du possible, on conserve ces polygones."
  },
  {
    "objectID": "src/seminaire-dirag/index.html#résultat-du-nettoyage",
    "href": "src/seminaire-dirag/index.html#résultat-du-nettoyage",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Résultat du nettoyage",
    "text": "Résultat du nettoyage"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#evolution-du-bâti",
    "href": "src/seminaire-dirag/index.html#evolution-du-bâti",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Evolution du bâti",
    "text": "Evolution du bâti\nPour estimer l’évolution de la population, on se penche sur l’évolution de la surface construite.\nPlusieurs approches considérées :\n\nCréations et suppressions “pures” : aucune intersection avec un bâtiment existant\nSoustraction du bâti de deux années distinctes\n\nC’est la deuxième approche qui est privilégiée car les créations pures peuvent passer à côté de l’étalement d’un quartier."
  },
  {
    "objectID": "src/seminaire-dirag/index.html#soustraction-du-bâti",
    "href": "src/seminaire-dirag/index.html#soustraction-du-bâti",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Soustraction du bâti",
    "text": "Soustraction du bâti"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#soustraction-du-bâti-1",
    "href": "src/seminaire-dirag/index.html#soustraction-du-bâti-1",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Soustraction du bâti",
    "text": "Soustraction du bâti"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#nettoyage-de-la-soustraction",
    "href": "src/seminaire-dirag/index.html#nettoyage-de-la-soustraction",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Nettoyage de la soustraction",
    "text": "Nettoyage de la soustraction\n\\[\n\\text{Indice de Compacite} = (4 * \\pi * \\text{Aire}) / (\\text{Perimetre} ^2)\n\\]\nSeuiller les polygones selon cet indice permet de supprimer les plus longilignes."
  },
  {
    "objectID": "src/seminaire-dirag/index.html#résultat",
    "href": "src/seminaire-dirag/index.html#résultat",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Résultat",
    "text": "Résultat\n\nOn obtient donc la différence de bâti d’une année à l’autre."
  },
  {
    "objectID": "src/seminaire-dirag/index.html#outils-utilisés",
    "href": "src/seminaire-dirag/index.html#outils-utilisés",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Outils utilisés",
    "text": "Outils utilisés\n\nProjet techniquement complexe pour diverses raisons :\n\nDonnées non traditionnelles\nVolumétrie des données\nBesoins ressources computationnelles élevées\nReproductibilité nécéssaire\n\nNécessité d’utiliser des technologies spécifiques, pas forcément dans le toolkit standard du statisticien\nPlateforme SSPCloud centrale pour la réalisation d’un tel projet\nProjet construit en 6 étapes séquentielles"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#chaîne-de-traitement",
    "href": "src/seminaire-dirag/index.html#chaîne-de-traitement",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Chaîne de traitement",
    "text": "Chaîne de traitement"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-1-acquisition-des-images-satellitaires",
    "href": "src/seminaire-dirag/index.html#etape-1-acquisition-des-images-satellitaires",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 1 : Acquisition des images satellitaires",
    "text": "Etape 1 : Acquisition des images satellitaires\n\nRécupération artisanale des images Pléiades :\n\nDemandes réalisées par mail à l’IGN, échanges via FTP\nGroupe DMRG créé sur Dinamis, mais non utilisé\n\nImages de Guyane via ST973\nDatation des images peu précise et non standardisée\nStockage des images orthos 8bits sur le SSPCloud"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-2-nettoyage-et-annotation-des-images",
    "href": "src/seminaire-dirag/index.html#etape-2-nettoyage-et-annotation-des-images",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 2 : Nettoyage et annotation des images",
    "text": "Etape 2 : Nettoyage et annotation des images\n\nPipeline Python  pour formatter les images brutes :\n\nSélection des images pour une zone d’intérêt\nSuppression des images ennuagées\nDécoupage des images \\(125m \\times 125m\\)\n\nPipeline de labellisation des images satellites avec la BDTOPO\nAutomatisation avec Argo Workflow"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-3-modélisation-et-entraînement",
    "href": "src/seminaire-dirag/index.html#etape-3-modélisation-et-entraînement",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 3 : Modélisation et entraînement",
    "text": "Etape 3 : Modélisation et entraînement\n\nEntraînement avec le package Pytorch\nSuivi et comparaison des modèles avec MLFlow\nUtilisation GPU indispensable (10h d’entraînement sur le SSP Cloud)\nAutomatisation avec Argo Workflow"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-4-inférence-du-modèle",
    "href": "src/seminaire-dirag/index.html#etape-4-inférence-du-modèle",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 4 : Inférence du modèle",
    "text": "Etape 4 : Inférence du modèle\n\nUtilisation de MLFlow pour l’entrepôt de modèle\nDéploiement d’une API pour réaliser l’inférence pour :\n\nune image donnée\nun îlot donné\nun contour géographique donné\n\nDéploiement continu de l’API avec ArgoCD\nRéalisation de l’inférence sur l’ensemble des images en parallèle avec Argo Workflow"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-5-mise-à-disposition-des-résultats",
    "href": "src/seminaire-dirag/index.html#etape-5-mise-à-disposition-des-résultats",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 5 : Mise à disposition des résultats",
    "text": "Etape 5 : Mise à disposition des résultats\n\nDéploiement d’un Geoserver pour mettre à disposition les fichiers géographiques (images et prédictions)\nDéveloppement d’une application React pour visualiser les résultats\n\nCRATT"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-6-analyses-des-résultats-selon-les-cas-dusages",
    "href": "src/seminaire-dirag/index.html#etape-6-analyses-des-résultats-selon-les-cas-dusages",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 6 : Analyses des résultats selon les cas d’usages",
    "text": "Etape 6 : Analyses des résultats selon les cas d’usages\n\nTravail statistique sur les prédictions :\n\nDétection des zones à forte créations/disparitions\nProduction de statistiques par îlot\nEvaluation des résultats\n\nDépendant des cas d’usages, quelles priorisations ?"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#en-résumé",
    "href": "src/seminaire-dirag/index.html#en-résumé",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "En résumé",
    "text": "En résumé\n\n🛠️ Multitude d’outils à utiliser :\n\nKubernetes, Docker, stockage MinIO, API, ArgoCD, Argo Workflow, MLFlow, React…\n\n… mais dont le coût d’apprentissage est rapidement rentabilisé :\n\nTechnologies “state of the art”\nDe plus en plus utilisées à l’Insee (LS3)\n\n⚠️ Coût de maintenance élevé ! Compétences rares à l’INSEE (ou ailleurs ?)"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#résultats-de-lexpérimentation",
    "href": "src/seminaire-dirag/index.html#résultats-de-lexpérimentation",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Résultats de l’expérimentation",
    "text": "Résultats de l’expérimentation\n\nRésultats prometteurs pour le soutien de l’enquête cartographique\nPremière utilisation des algorithmes effectuée par la DMTR pour prioriser l’envoi d’agents sur le terrain\nOpportunité pour le soutien des estimations de population à Mayotte\nParti pris de présenter une chaîne complète de production en guise de POC !\nChoix rapides ➡️ nombreuses améliorations possibles"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-1",
    "href": "src/seminaire-dirag/index.html#etape-1",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 1",
    "text": "Etape 1\n\n\n\n\n\n\nLes données Pleiades dont nous disposons sont fournies par l’IGN et ne sont datées qu’à l’année\nTravail à fournir pour maîtriser l’acquisition de données PLEIADES\nIndispensable si on veut des estimations précisément datées"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-2",
    "href": "src/seminaire-dirag/index.html#etape-2",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 2",
    "text": "Etape 2\n\n\n\n\n\n\nLe nettoyage (filtering des nuages, normalisation) doit être consolidé et demande validation\nAnnotation ou récupération d’autres données annotées, 2 possibilités :\n\nAméliorer les annotations actuelles manuellement\nRécupérer d’autres images annotées ou annotations pour nos images"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-3",
    "href": "src/seminaire-dirag/index.html#etape-3",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 3",
    "text": "Etape 3\n\n\n\n\n\n\nAméliorations secondaires par rapport à l’amélioration de la qualité des annotations\nSuivre l’état de l’art à l’affût de nouveautés (modèle pré-entraînés sur HuggingFace)"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-4",
    "href": "src/seminaire-dirag/index.html#etape-4",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 4",
    "text": "Etape 4\n\n\n\n\n\n\nAPI à développer au delà du prototype actuel en fonction des besoins des clients"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-5",
    "href": "src/seminaire-dirag/index.html#etape-5",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 5",
    "text": "Etape 5\n\n\n\n\n\n\nApplication de visualisation à développer au delà du prototype actuel en fonction des besoins des clients"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#etape-6",
    "href": "src/seminaire-dirag/index.html#etape-6",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "Etape 6 :",
    "text": "Etape 6 :\n\n\n\n\n\n\nAnalyse des résultats encore insuffisante et à pousser"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#en-plus",
    "href": "src/seminaire-dirag/index.html#en-plus",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "En plus",
    "text": "En plus\n\nSentinel 2 : Poursuite des travaux de Judith Nabec sur images Sentinel 2 plus simples d’acquisition, et à résolution spectrale plus élevée (ou sur d’autres images)"
  },
  {
    "objectID": "src/seminaire-dirag/index.html#la-suite",
    "href": "src/seminaire-dirag/index.html#la-suite",
    "title": "Travaux exploratoires avec des données satellites : Bilan des résultats obtenus",
    "section": "La suite",
    "text": "La suite\n\nFin de la phase d’expérimentation\nBeaucoup de cas d’usage identifiés et de clients finaux\nNécessité de monter un véritable projet pour chaque cas d’usage avec des moyens adaptés\nCe qui permettra de hiérarchiser les améliorations"
  }
]